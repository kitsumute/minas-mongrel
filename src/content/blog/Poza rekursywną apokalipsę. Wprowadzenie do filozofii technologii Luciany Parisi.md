---
title: Poza rekursywną apokalipsę notatki
isDraft: true
description: notka
pubDate: 29 November 2023
coverImage: ../../assets/neon.png
coverAlt: description
tags:
  - notka
---

1a

Od pierwszego sygnowanego tekstu w ramach CCRU[^1] Parisi bada relację między produkcją wiedzy a technologią jako czymś pomiędzy nieludzką siłą, autonomicznym podmiotem a warstwą organizacji złożoności o nieostrych granicach, na których raz bardziej przypomina instrument rozsądku lub przedłużenie ciała, a raz obcą inteligencję[^2]. Ta idea nieludzkiej technologii powraca w *Abstract Sex*, gdzie Parisi zrewidowała stratyfikację seksualności z perspektywy cyberseksu, którym ciekłokrystaliczne ekrany w 2004 wciąż jeszcze połyskiwały ekscytującymi potencjalnościami dla przekodowania tożsamości płciowej oraz reprodukcji społecznej. W *Contagious Architecture* przeniosła ona uwagę z biocyfrowego pogranicza kapitalizmu na transformacje produkcji wiedzy w modelach automatycznej komputacji, która poprzez "abstrakcyjne choć realne (...) cyfrowe czasoprzestrzenie programuje formy architektoniczne i infrastrukturę miejską, a przez to także sposoby życia"[^3]. Od tamtego czasu Parisi w kolejnych artykułach sonduje problem tego, jak możliwe jest myślenie technologii wobec tego, że technologie algorytmiczne służą kapitalizmowi do wieczystego zniewolenia każdej formy inteligencji?

Na polu krytyki rozumu instrumentalnego, będącej stałym punktem odniesienia Parisi, pytanie "czy maszyna może myśleć?" zostaje przekształcone w "czy istnieje myślenie po zinstrumentalizowaniu rozumu przez maszyny?". Katastroficzne poczucie zagrożenia spowodowane narastającą automatyzacją funkcji kognitywnych i sensomotorycznych właściwie od samego początku towarzyszy podmiotowi nowoczesnemu, ale dopiero cybernetyka realnie postawiła pod znakiem zapytania naturę myślenia, kwestionując rolę zarówno filozofii jak i organizmu społecznego w nadchodzącym neo-świecie. Problem cybernetyki jako pierwszy z pełną świadomością jego wagi sformułował Heidegger, stwierdzając, że w technologiach informacji podmiot myślenia staje się komponentem zautomatyzowanych układów sprzężonych ze środowiskiem jako zasobem cyfrowych danych. Przeformułowanie myślenia w kategoriach przetwarzania informacji - będące efektem i katalizatorem postępującego wyzysku, alienacji i coraz ściślejszej kontroli pragnień - sprowadzało je do użyteczności dla systemu, co zdaniem wielu powojennych teoretyczek i teoretyków niosło niebezpieczeństwo całkowitego zaniku zdolności krytycznego myślenia. Jeśli cybernetyka, jak często sama postuluje, faktycznie za sprawą zautomatyzowanych form poznania pomija fundamentalną dla krytyki autonomię poznania konceptualnego, to czy możliwe jest myślenie po cybernetyce?

Odpowiedź Parisi biegnie wbrew niemal całej tradycji filozofii techniki i teorii krytycznej, poza rozproszonymi wyjątkami, jak Gilbert Simondon[^4], CCRU[^5], McKenzie Wark czy David Roden[^5]. Podczas gdy w podejściu post-heideggerowskim, od Szkoły Frankfurckiej przez Baudrillarda i Agambena po Stieglera i Pasquinelliego, krytyka technologii prowadzi do wykazania, że ostatecznie myślenie *po* promieniuje tylko z myślenia *poza/sprzed/przeciw*, dla Parisi możliwość myślenia *po* już jest technologią, mieszaniną jednorodną, której składniki stworzyły płaszczyznę spójności z nowymi potencjalnymi formami myślenia. Zamiast unieważniać możliwość myślenia, algorytmiczna komputacja komplikuje warunki wiedzy. Odpowiedź na problem automatyzacji poznania i kontroli wektorów informacji musi uwzględniać już zachodzące przekształcenia tego, jak pojmujemy myślenie i podmiot wiedzy, pod wpływem istniejących praktyk obliczeniowych algorytmów.

Za postulatem myślenia z wnętrza planetarnej infrastruktury komputacji podąża oś krytyczna filozofii Parisi: infrastruktura ta rozwija technologie i modele wiedzy zaprojektowane zgodnie z obrazem Uniwersalnego Człowieka, rzutowanym przez nowoczesną episteme dla kontroli innych form inteligencji. O ile w filozofii techniki i teorii krytycznej zazwyczaj eksponuje się układy technologiczne umożliwiające dominację systemu władzy w imię określonego ideału życia społecznego, Parisi chce przesunąć tę krytykę do wnętrza technologii (nawet nie organologicznie pojętej techniki jako eksterioryzacji i prostetyki ciała, lecz do wnętrza automatycznej komputacji). Dzięki temu, że ideą regulatywną krytyki Parisi jest obce myślenie pleniące się wnętrzu  transcendentalnej architektury, jej metoda badawcza utrzymuje łącze z tradycją krytyczną przy jednoczesnej wierności futurystycznemu impulsowi spekulacji. Postdeleuzjańskie przymierze Krytyki ze Spekulacją kreśli tu schemat na wyjście z gmachu teorii krytycznej, z pominięciem pułapek zarówno nowomaterialistycznych fabulacji o utopijnej "możliwości innego myślenia", niemającego żadnej mocy określania aktualnego systemu wiedzy-władzy, jak i dominujących w środowiskach Sztucznej Inteligencji nie-krytycznych wizji przyszłości sunącej w technologicznym nadbiegu kapitalizmu. W efekcie, Parisi konstruuje sobie pozycję, z której zaznacza się niepokojąca analogia między krytykami rozumu instrumentalnego a użyciem technologii w kapitalizmie. W obu reprezentacjach, krytycznej i panującej, zrównuje się formy automatycznej inteligencji z logiką systemu przekreślając możliwość autonomicznego myślenia technologii. Tylko przekraczając kategorię instrumentalności i ujawniając warunki technoróżnorodności w ramach samych technologii automatycznej komputacji - jako projektowania i wywoływania innych logik, innych kosmokomputacji - możemy podważyć te same struktury myślenia, które formatują relacje na rynku pracy, dostęp do kapitału kulturowego i reprezentacje generowane w platformowych architekturach algorytmicznych.

1b
Przedstawiona w *Kolonializmie rekursywnym i kosmokomputacji* koncepcja zakłada proces stratyfikacji wiedzy, w której określone mechanizmy i procesy powtarzają się w różnych warstwach organizacji myślenia. A zatem, instrumentalizacja władz poznawczych, pragnień i technik jest sprzężona z globalną ekspansją nowoczesnego uniwersalizmu. Szczytowym wyrazem tego paradygmatu epistemicznego była filozofia transcendentalna Kanta wraz z następującym idealizmem, która ugruntowała burżuazyjną ideę Człowieka Uniwersalnego w teorii samoświadomego podmiotu transcendentalnego. Paradygmat ten dostarczał moralnego uzasadnienia m.in. dla rasistowskich rozróżnień fundujących nauki przyrodnicze oraz urasowionego wykluczenia konkretnych podmiotów z postępu historii w naukach społecznych i humanistycznych. Z jednej strony nauka i historia jako warstwy w produkcji wiedzy służyły za podstawę dla kolonialnej dystrybucji pracy, a z drugiej - stanowiły integralny czynnik postępu technologicznego, nieraz decydujący o szczegółowych rozwiązaniach inżynieryjnych. Tym samym, rozwój historyczny, postęp w naukach i rewolucje technologiczne zwrotnie reprodukowały i wzmacniały rasistowskie założenia nowoczesności:
	*To właśnie w imię aksjomatyki nowoczesnej nauki technologia stała się miarą postępu, względem której mierzy się zglobalizowany świat. Samoustanowiona uniwersalność zachodniej technologii mieści się w ramach epistemologii kapitalizmu rasowego opartego na zasadach przyczynowej skuteczności.*

Z każdą rewolucją technologiczną - parową w XVIII wieku, elektryczną w XIX, informatyczną w XX - poszerzał się koncentryczny ruch reprodukcji kapitału wokół skolonizowanego globu. Wraz z przesuwaniem granic kapitalizmu, nie tylko w sensie geograficznym, ale także libidinalnym i nooetycznym, nowe technologie przynoszą nowe wypadki, których ryzyko rozkłada się wzdłuż urasowionych linii odwzorowania Uniwersalnego Człowieka. W tym sensie nowoczesna wiedza jest krajobrazem pouderzeniowym oglądanym przez apokalipyczny obiektyw. Estetyka apokalipsy  rzuca samookreślający się podmiot historii Zachodu w przestrzeń liminalną, gdzie katastrofy trwają w stanie nieskończonego nadciągania w nieokreślonej przyszłości. Jednocześnie fundamentalne niedookreślenie tej przestrzeni liminalnej staje się pretekstem racjonalizującym ciągłe zaostrzanie środków kolonialnej przemocy (co zostaje nam przypomniane przy okazji każdego kryzysu, krachu, kataklizmu i pandemii). W dzisiejszej planetarnej infrastrukturze komputacji ta rasistowska przemoc logiki inkluzji/ekskluzji (zarówno w programach klimatycznych jak i komputerowych) przyjmuje formę kontroli wektorów informacji i analizy ruchów użytkowników platform za pomocą algorytmów predykcyjnych.

We wszystkich warstwach produkcji wiedzy powraca logika rekursywna.
	*Rekursja to pojęcie, które od dawna jest obecne w teoriach cybernetycznych. W swojej podstawowej formie rekursja odnosi się do pętli sprzężeń zwrotnych między wyjściami a wejściami systemu. Można ją także opisać jako krok lub funkcję w ramach procedury wywołującej z powrotem samą tę procedurę.* 

Rekursywność jest właśnie jednym z takich mechanizmów, poprzez który Parisi zwraca uwagę na izomorfizm i przechodniość określonej logiki pomiędzy różnym warstwami wiedzy i władzy, która to logika ustanawia post-oświeceniową i europejską kosmotechnikę, tj. konkretny zestaw technik jako metafizyczne ramy myślenia. Rekursywność powraca więc w kapitalistycznej formule M-C-M, w charakterystycznej dla filozofii transcendentalnej syntezie Innego na gruncie Tego Samego, w urasowionej "onto-epistemologicznej autoimmunizacji Człowieka Uniwersalnego", w apokaliptycznym odnawianiu się końca świata, w sprzężeniach zwrotnych systemów nadzoru i kontroli, w algorytmicznym przetwarzaniu cyfrowych danych. Jako kosmotechnika, "rekursywne technologie stanowią tryby i systemy myślenia – to technologiczne episteme, które umożliwia zmieniające się to samo uniwersalnej epistemologii". *Tym samym* tutaj jest struktura celowościowa kapitalizmu rasowego, reprodukującej się dzięki technologiom rekursywnym, które przekształcają praktyki społeczne w środki do rozprzestrzeniania metafizycznego modelu Uniwersalnego Człowieka. Ten mechanizm instrumentalizacji przekłada się również na szczególną dla nowoczesnej kosmotechniki rekursywności relację z zewnętrzem. W rekursji złożony problem rozwiązuje się przez dzielnie go na mniejsze części: znaną i nieznaną, a następnie ponawianie tego ruchu dla części nieznanej, cały problem będzie składał się z wielu prostych części, które przypominają znaną podstawę. W ten sposób nowoczesna kosmotechnika przyswaja inność, obcość, czarność, nieludzkość, nieświadomość - segmentuje zgodnie z logiką inkluzji/ekskluzji, aż zostaną opanowane w reprezentacji różnicy jako koniecznego momentu w reprodukcji tożsamości kapitalizmu rasowego (PRZYPIS NIEŚWIADOMOSĆ TO TAK NAPRAWDĘ EDYP W ODCINAKCH, OBCE KULTURY ANALIZOWANE PRZEZ ANTROPOLOGIĘ ETC).

Ta sama logika rekursywna, która pozwala jasno zdefiniowanemu wnętrzu systemu - jak podmiot uniwersalny w kolonializmie - adaptować się do zewnętrza poprzez instrumentalną reprezentację różnicy w produkcji wiedzy, nasycają system przygodnością. Nawet jeśli różnica w formie orientalności lub Czarności zostaje przedstawiona przez kolonializm jako negatywny wskaźnik w relacji do białego podmiotu uniwersalnego, to wytwarzane w tej procedurze efekty nie dają się w zupełności wyjaśnić w kategoriach tożsamości. Im bardziej proces produkcji wiedzy dąży do zachowania tożsamości systemu, tym więcej nie-tożsamościowych różnic musi przyswoić. Dlatego, pomimo założonego programu autoimmunologicznej tożsamości, przygodne zewnętrze zmusza również system do adaptacji (np. rekursja w XIX wieku ugruntowana była w dedukcyjnym rozumie, w XXI - w indukcyjnych wzorcach danych). Tak jak kapitalizm wytwarza immanentnie mroczną nieświadomość schizofrenii, tak kolonializm „rekonstruuje swoje wnętrze w liminalnej przestrzeni apokaliptycznej autodestrukcji”. W jednym i drugim przypadku konieczne jest stałe dodawanie kolejnych reguł, które pozwalają nadkodowywać i kontrolować „przestrzeń liminalna tego, co nieznane” (stanie się to jasne, gdy poniżej omówimy tzw. problem stopu), tak aby katastrofalny rozpad systemu wiecznie zagrażał, ale nigdy się nie ziścił. Ten imperatyw brutalnego nadkodowywania nieokreślonej przestrzeni przez transcendentny aksjomat powraca w logice i matematyce, a przez to także w infrastrukturze komputacji i architekturach algorytmicznych. Powodem tej jednocześnie abstrakcyjnej i namacalnej przemocy systemu jest liminalna przestrzeń jako przygodność w samym jądrze rozumowań algorytmicznych, związana z niemożliwością obliczenia (w skończonym czasie) wszystkich możliwych wzorców w danych i koniecznością spekulacji w podejmowaniu decyzji przez automatyczną maszynę. Ta komputacyjna przygodność wdziera się do społecznych układów komunikacji poprzez LLM-y, środowiska programowania, uczenie maszynowe, infrastruktury algorytmiczne i platformy społecznościowe, które - jako praktyki społeczne - w coraz większym stopniu uczestniczy w produkcję wiedzy i podmiotowości.

Rozmontowywanie instrumentalnego podejścia do automatycznych form inteligencji wyznacza kluczowy moment projektu filozoficznego Parisi, ponieważ stratyfikacja produkcji wiedzy w ramach kosmotechniki rekursywności, a poprzez środowiska technomedialne jak aplikacje i platformy, odpowiada za to, że "logika komputacji (…) przenikania do kultury". Dlatego proponuje postinstrumentalne pojęcie kosmokomputacji, aby modelować kolejne pole ustanawiania władzy oraz stawiania jej oporu, nawigacji między jej punktami kontroli lub przeprogramowywania jej technik.

1c

Koncepcja kosmokomputacji Parisi jest odpowiedzią na bezradność teorii krytycznej, która postawiona przed możliwością myślenia technologii komputacji potrafi jedynie ściągnąć ze strychu wyświechtaną krytykę rozumu instrumentalnego. W spadku po Szkole Frankfurckiej i Heideggerze otrzymała ona przekonanie, że modelem epistemologicznym nowoczesności jest postępująca racjonalizacja przyrody i myślenia. Wody Renu, mysz w laboratorium i blockchainowy las łączy rozumowo określona forma, dzięki której pewne potencjały natury mogły zostać podłączone do rynkowego obiegu kapitału. W metafizyce środków i celów rozumu instrumentalnego każdy byt sprowadza się do instrumentu w teleologicznym projekcie technicznego opanowywania rzeczywistości zgodnie z subiektywnym rozumem burżuazji. Przyroda i myślenie stają się więc zasobami, które należy mierzyć, klasyfikować, kategoryzować, a w końcu zaadaptować do dalszego postępu technonaukowej neutralizacji przygodności.

Punktem kulminacyjnym w progresywnym ruchu nowoczesnej racjonalizacji jest automatyzacja inteligencji nabierająca rozpędu wraz z cybernetyką, tj. nauką o kontroli i komunikacji, dla której byt znaczy tylko jako zbiór informacji. "Rozumowanie instrumentalne cybernetyki, zastępując sądy wyprowadzone z założonych kategorii realizowaną przez maszyny operatywnością stanów prawdy, wchłania całkowicie zachodnią metafizykę". Idee nie są już "przedstawiane lub udowadniane, lecz przetwarzane jako informacje", dlatego cybernetyka jako "nowa technonauka komunikacji, uruchamia nowy język myśli wbudowany w wejścia i wyjścia obwodów informacji, zgodnie z którymi programuje się działania w celu osiągnięcia serii rezultatów". W układach cybernetycznych wiedza nie potrzebuje już ugruntowania w apriorycznej syntezie podmiotu refleksji, ponieważ powstaje w rezultacie automatycznego przetwarzania cyfrowych, binarnych, dyskretnych danych. Odkąd "cybernetyka przekształca mowę w wymianę wiadomości", język i myślenie można również zredukować do "sterowanych i sterujących instrumentów informacji." 

Od Heideggera po Stieglera filozofia techniki dążyła do zniuansowanego pojęcia techniki, które odróżniałoby istniejące sposoby użycia urządzeń technicznych od możliwości innego myślenia, zarówno uwarunkowanego jak i wyzwalanego przez techniczność jako taką. Z racji tego, że cybernetyka (jako teoria i praktyka konstrukcji działających automatów) zagrażała autonomii myślenia domniemaną funkcjonalną jednoznacznością i jednorodnością wymiany informacji, filozofia techniki w imię ochrony życia przed całkowitym podporządkowaniem rozumowi instrumentalnemu zatrzymywała się przed afirmatywnym ujęciem automatycznych form poznania. "Jako że automatyczność sytuuje się na mrocznej krawędzi filozofii, twierdzi się, że stoi ona albo po stronie negatywności wykluczenia jako bezmyślne serwomechaniczne narzędzie, albo po stronie dominującej władzy jako środek zwiększania przemocy kapitału lub aparatu państwa (za pomocą ideologicznych, dyskursywnych lub afektywnych metod)" (Recursive Philosophy and Negative Machines). Alternatywa ta będzie stale powracała w krytyce technologii, tak jak typowy dla teorii krytycznej pozytywny program, postulujący "konieczność innego myślenia", będący echem postawionego w odpowiedzi na cybernetykę "zadania" uczenia się innych sposobów myślenia. W momencie gdy infrastruktura środków produkcji uzależniona jest od wektorów informacji organizowanych przez automatyczną komputacji, a warunki podmiotowości zanurzone są w mediach społecznościowych, to miejsce, skąd ma się wybiegać inne myślenie, zbyt często pozostaje niedookreślone, przez co opór przeciw kapitalizmowi czy ujście ku jakiejkolwiek niedystopijnej przyszłości muszą wydawać się kompletnie beznadziejne. Jak zaznacza Parisi, w znacznej mierze winę za to ponosi bezwiedne przyjęcie nowoczesnej reprezentacji technologii jako instrumentu racjonalizacji i uniwersalizacji samookreślonego podmiotu transcendentalnego. Po tym ruchu negacji można już tylko liczyć na eschatologiczną instancję "nie z tego świata", która będzie w mocy go odmienić.

Parisi zarzuca więc teorii krytycznej, że zachowuje ona podział - widoczny w tekstach np. Antoinette Rouvroy, kolektywu Tiqqun, Alexandra Gallowaya czy Mateo Pasquinelliego - na autonomiczne (odkrywające nowe przestrzenie) myślenie i automatyczne (zdeterminowane) procedury algorytmów, które poświęcają krytykę i refleksję na ołtarzu rozumu instrumentalnego. Po uwzględnieniu przygodności w warunkach automatycznej racjonalności „nie da się już utrzymać teorii krytycznej, która zarzuca komputacji redukcję ludzkiego myślenia do samych mechanicznych operacji”. Założenie typowej dla filozofii nowoczesnej dychotomii między źródłową przygodnością a technologicznym rozumem instrumentalnym pociąga za sobą następną istotną tu tezę teorii krytycznej: w algorytmicznych procedurach przetwarzania danych dochodzi do zrównania myślenia i działania. Powtarza się tutaj znany argument Heideggera: dominacja technologicznego myślenia podporządkowuje możliwości innego myślenia jednemu modelowi czystej efektywności. Toteż teoria krytyczna przekonuje, że źródłem przygodności miałoby być tylko to, co nie poddaje się automatyzacji i komputacji, a co przyjmuje się za punkt oporu przed instrumentalizacją życia społecznego, jak ciało, spontaniczność, natura lub kultura. Tymczasem, rozum instrumentalny, którego najnowszym nośnikiem i urządzeniem jest – za Rouvroy – algorytmiczne rządzenie, ma realizować teleologię postępu nowoczesności w technologicznym i naukowym poskramianiu natury oraz kapitalistycznym zawłaszczaniu stosunków społecznych w formie fetyszyzmu towarowego. Z tą krytyką komputacji opartą na oddzieleniu przygodności (której schronieniem jest ciało, afekt lub niewyrażalność bycia) od automatycznego wnioskowania wiążą się jednak dwa problemy.

Po pierwsze, ostateczny przedmiot tej krytyki, czyli kapitalizm, dawno już przekroczył założoną dychotomię, odrzucając rozum dedukcyjny i optymalizując kontrolę nad przepływami informacji dzięki m.in. teorii systemów dynamicznych, teorii gier czy paradygmatu _big data_. Infrastruktura komputacji z jej architekturami algorytmicznymi tworzy planetarną sieć przechwytywania zdolności kognitywnych i afektywnych w formie danych cyfrowych, które zostają wykorzystane do reprodukcji wektorów kapitału. Stąd, krytyki oparte na podziale przygodność/automatyczność tracą swoją moc eksplanacyjną, ponieważ codzienne doświadczenie użytkowników platform już dawno go przekroczyło. Przeoczanie tego procesu musi być jedną z głównych przyczyn porażki teorii krytycznej w XXI wieku.

Po drugie, przez „redukcję komputacji do podrzędnej mechanizacji rozumu, skazanej na zwykłą iterację i niezdolnej do zmiany”, teoria krytyczna sama wpada w technokapitalistyczną instrumentalizację rozumu i potwierdza dominującą reprezentację technologii. Parisi zauważa, że post-heideggerowską krytykę technologii łączy z formalistycznymi i neurokognitywnymi modelami maszynowej inteligencji obraz automatycznej komputacji jako czysto efektywnego wykonywania zaprogramowanych zadań. W obu ujęciach zakłada się, że architektury algorytmiczne, czy szerzej kapitalistyczna infrastruktura komputacji, polegają na zautomatyzowanym procesie decyzyjnym, w którym zanika różnica między myśleniem a działaniem. Algorytm nie byłby niczym innym niż odgórnie zakodowaną procedurą postępowania, skorelowaną już ze wzorcami istniejącymi w bazach danych. Uznając jednak taki obraz rozumowania algorytmów, akceptuje się – zdaniem Parisi – kapitalistyczną reprezentację produkcji dostępnej przestrzeni myślenia, a więc przewidziany przez kapitalizm rasowy podmiot wiedzy. W takim wypadku założenie zmiany społecznej jest równoznaczne z wyczekiwaniem spełnienia „mesjańskiej obietnicy” „pozbawionego twarzy, odłączonego, bezosobowego i obojętnego podmiotu”, którego „praktyki nieistnienia (…) miałyby nie mieć nic wspólnego" ze zautomatyzowaną komunikacją. Zamiast zgadzać się na pojęcie automatycznego poznania jako bezmyślnej komputacji, która pozbawia podmiot „transcendentalnego narzędzia rozumu”, Parisi proponuje rozważyć możliwości, jakie daje podważenie modelu samookreślenia podmiotu transcendentalnego przez zautomatyzowany proces decyzyjny. 

Z tej perspektywy, projekt teoretyczny Parisi jest próbą sformułowania afirmacyjnego podejścia do sztucznej inteligencji, które wskazuje na to, że układy maszynowe mają potencjał przeprogramowania podmiotowości przez eksplorowanie nieznanych obszarów myślenia za pomocą nieświadomościowych i automatycznych form rozumowania, a przez to wytwarzania innych kosmotechnik niż ta kolonializmu rekursywnego. Post-instrumentalne podejście Parisi uznaje fakt, że technologia służy kapitałowi i rozszerza przemoc rasową, projektowana i montowana wzdłuż rekursywnej logiki nowoczesnej kosmokomputacji. Lecz poprzez spekulatywne założenie autonomii technologii jako obcego podmiotu poznania, którego nie można zredukować do poznania podmiotu refleksji, paradoksalnie może skierować krytykę relacji władzy w funkcjonowaniu infrastruktur techno-medialnych głębiej i precyzyjniej, niż pozwala na to krytyka rozumu instrumentalnego, która w punkcie wyjścia zakłada tożsamość technologii i nowoczesnej racjonalizacji kapitalizmu. Aby opracować wraz z obcą inteligencją inną kosmokomputację, konieczne jest "nowe wyobrażenie tego, jak myśleć w epoce automatycznego poznania", a to wymaga rozpoczęcia od pragmatystycznego przedefiniowania algorytmów jako praktyk społecznych o immanentnym wymiarze abstrakcyjnej przygodności.

2a
Zgodnie z klasyczną definicją, algorytm jest skończoną sekwencją poleceń koniecznych do realizacji zadania. Tym, co odróżnia algorytm od zwyczajnych metod obliczeniowych (określonych przez jakiś zestaw reguł), jest dodatkowo wbudowana w algorytm tzw. zasada stopu, czyli mechanizm zakończenia działania w skończonej liczbie kroków[^6]. Algorytmy mogą różnić się porządkiem bramek logicznych (I, LUB, JEŚLI…TO…, NIE), językiem formalnym oraz metodą komputacji, ale schemat funkcjonowania każdego będzie następujący: na początku algorytm otrzymuje dane wejściowe, następnie przechodzą one przez skończoną liczbę dobrze zdefiniowanych etapów obliczania i wnioskowania, a po uzyskaniu danych wyjściowych algorytm się zatrzymuje. Procedura się powtarza: to funkcja rekursywna algorytmu. Przejście od stanu wejściowego do wyjściowego może być zarówno deterministyczne, jak i losowe, tj. albo zachodzi przechodniość od wejścia do wyjścia, albo wprowadzana jest do danych losowość, która przerywa ciągłość przekształceń pomiędzy wejściem i wyjściem.

Współczesne pojęcia algorytmu – jak np. w algorytmicznej teorii informacji Gregory'ego Chaitina – mają źródło w debatach wokół komputacji z lat 30. ubiegłego wieku, kiedy to przedstawiono wiele matematycznych rozwiązań tzw. problemu decyzyjnego Hilberta. Dowodzono wtedy, że nie jest możliwe sformułowanie takiego algorytmu, który będzie mógł rozstrzygnąć o każdym możliwym twierdzeniu, czy jest prawdziwe i dowodliwe w logice kwantyfikatorów, czy nie. Hilbert zamierzał przedstawić pewne i niezmienne podstawy matematyki, której wszystkie twierdzenia dałyby się zapisać w precyzyjnym języku formalnym i podporządkować dobrze zdefiniowanym regułom. Jeśli rozumowanie zawsze prowadziłoby do wniosku rozstrzygającego o prawdzie lub fałszu twierdzenia, to system, w którym je sformułowano, byłby zupełny i niesprzeczny. W 1931 roku Kurt Gödel sformułował jednak twierdzenie o niezupełności, wykazując, że nie istnieje niesprzeczny system formalny, taki jak aksjomatyka Hilberta, który udowadniałby swoją zupełność wyłącznie na mocy własnych założeń. Jak wynika więc z twierdzenia Gödla, udowodnienie niesprzeczności i zupełności systemu formalnego zakłada kolejny dowód, którego nie obejmuje przyjęty początkowo system aksjomatów. Zbiór zdań prawdziwych nigdy nie będzie równy zbiorowi zdań dowodliwych. Każdy system formalny będzie zatem zawierał zdania prawdziwe, których nie można udowodnić; każdy zbiór aksjomatów będzie niekompletny.

Alan Turing przeformułował twierdzenie Gödla na tzw. problem stopu. Dotyczy on analogicznej niemożliwości określenia z góry, czy dojdzie do zatrzymania obliczeń algorytmu w skończonym czasie, czy algorytm będzie je ponawiał w nieskończoność. Turing wykazał, że nie istnieje taki algorytm, który rozwiązywałby problem stopu dla każdego możliwego programu, tj. niemożliwe jest rozstrzygnięcie, czy każda maszyna może dokończyć swoje obliczenia w skończonym czasie. Turing odkrył tym samym, że dla każdego algorytmu pewne twierdzenia będą niemożliwe do obliczenia, tj. niekomputowalne w skończonym czasie i niekompresowalne do mniejszego ciągu znaków (algorytmu krótszego od przetwarzanych danych). Oznacza to, że program nie może poznać wyniku z wyprzedzeniem, musi przeprowadzić cały proces komputacji, by wygenerować wzorzec zawarty w przetwarzanej bazie danych, a jeśli musi podjąć decyzję w czasie krótszym, niż czas konieczny do przetworzenia całości zbioru, wtedy wygenerowany wzorzec będzie spekulatywną i przygodną hipotezą.

Gregory Chaitin, amerykański inżynier komputerowy i matematyk, zaaplikował problem stopu Turinga do teorii informacji Shannona dowodząc, że algorytmiczna komputacja nie polega na potwierdzaniu pewnych i oczywistych aksjomatów. Przeciwnie, algorytmy komputerowe zawsze „napotykają ścianę danych, których nie można zsyntetyzować do mniejszych wielkości”, co „ujawnia niekompletność aksjomatyki, w której program został postawiony”. Algorytm przetwarzając dane musi w końcu zatrzymać się na jakimś stanie o wartości 0 lub 1, którego nie zakodowano z góry w warunkach początkowych programu. Stan ten jest hipotezą algorytmu na temat zbioru danych, „binarną ekspresją” (0,1) decyzji o kompresji nieskończonych wielkości prawdopodobieństw (np. 9/44 = 0,20454545...) do liczb naturalnych (tj. 0,1)). Z tego wynika, że „to, co niekomputowalne, określa granice komputacji”, rozciąga przestrzeń liminalną dla algorytmicznych wnioskowań. Te niekomputowalne wielkości, czyli wyrażone w binarnej formie algorytmicznie losowe i nieskończone ciągi cyfr, Chaitin nazywa liczbami Omega (Ω). Dlatego:

*architektur algorytmicznych nie używa się po prostu do tworzenia profilów w oparciu o wcześniej ustalone zestawy algorytmów, ale do wykorzystywania samo-ograniczającej się mocy komputacji, określonej przez ich zdolność do zdecydowania o tym, kiedy program ma się zatrzymać, poprzez przekształcanie niepoliczalnych nieskończoności w losowe dyskretne jedności...*

"Samo-ograniczająca się moc komputacji" zamienia liminalne przygodności w wzorce poznania, a algorytmiczne wnioskowania w eksperymentalne praktyki. Eksperymentalność ta przejawia się w tym, że w procesie algorytmicznej komputacji nie tylko zostaje powtórzona zakodowana wcześniej forma algorytmu jako granica komputacji i wzorzec danych, do którego ma dążyć uczenie się programu, ale także w koniecznym stawianiu hipotez o danych. W obliczaniu tych hipotez założona jest możliwość popełnienia błędu, wynikająca z problemu liczby Ω Chaitina, tj. niekompresowalnych wielkości. Algorytm – jako wzorzec uzyskany w procesie uczenia na podstawie treningowej bazy danych – nie jest więc ani ściśle formalnie zakodowanym obiektem matematycznym, ani jednoznacznym odwzorowaniem wzorców już istniejących w bazach danych, lecz raczej należałoby go „określić przez immanencję nieskończoności w skończonych zbiorach danych”.

Algorytmiczna teoria informacji Chaitina pozwala Parisi zakwestionować obraz algorytmów jako procedur do potwierdzania znanych prawd. O algorytmicznej komputacji należałoby raczej mówić jako o praktyce eksperymentalnej, spekulatywnej i heurystycznej, która „nie tylko jest narzędziem do projektowania, lecz w rzeczywistości stała się samym projektowaniem”; sama jest wzorcowaniem wzorców, uczeniem się uczenia i zadaniem myślenia. Istnienie liczby Omega w rdzeniu komputacji oznacza, że przygodność nie jest zewnętrznym błędem, lecz wewnętrznym warunkiem automatycznej komputacji, który pozwala algorytmom dochodzić do wniosków informacyjnie bogatszych niż przesłanki, z których rozpoczęły wnioskowanie. Algorytmiczny proces decyzyjny nie tylko rozszyfrowuje istniejące już w danych wzorce, ale także produkuje dane pozbawione wzorców, które warunkują powstawanie informacji spoza granic form naoczności samookreślającego się podmiotu transcendentalnego. Dlatego jeśli kolonializm rekursywny opiera się na przygodności w algorytmicznej komputacji, to wplecione w jego funkcjonowanie są „sieci aktualnych okazji” dla doświadczenia i myślenia tego, co zewnętrzne wobec wiedzy założonej w onto-epistemologicznych przesłankach Człowieka Uniwersalnego. Odkąd algorytmiczne poznanie i automatyczna komputacja stały się kluczowe dla kontroli wektorów informacji w kapitalizmie rasowym, "zadaniem myślenia" jest badanie stanowisk w logice i modeli algorytmicznych, które projektują kosmokomputacje z przyszłości, poza apokaliptyczną rekursywnością przyjętych uniwersalistycznych, standaryzujących i wykluczających programów kapitalizmu rasowego.

3

W omawianym tekście z Ezekielem Dixon-Románem Parisi posługuje się dwoma ideami Yuka Huia, by sformułować pozytywny program post-instrumentalnego podejścia do automatycznej inteligencji. W *Rekursywności i przygodności* Hui przedstawia nowoczesny model myślenia - rekursywną logikę - jako szczególny sposób organizacji technik, który pozwala na ciągłe przyswajanie nowych wypadków i przygodnych zdarzeń bez porzucania transcendentalnej struktury. We wszystkich artykulacjach nowoczesności, jak kapitalizm, kolonializm, nauki ścisłe lub humanizm, a także na wszystkich warstwach stratyfikacji wiedzy, od architektur algorytmicznych przez dystrybucję środków produkcji po obraz uniwersalnego Człowieka, zawarta jest funkcja rekursywna, która dzieląc i kategoryzując promienie akcydentalnego zewnętrza jednocześnie otwiera kolejne okna przygodności w procedurach reprodukcji systemu. Wewnętrzna techno-logika (rekursja + inkluzja/ekskluzja) raz za razem wywiera na kapitalizmie i kolonializmie presję do zniewalania, dyscyplinowania i kontroli przygodności generowanej w jego wnętrzu, a grożącej apokaliptycznym przeciążeniem. Gdyby jednak paradygmat epistemologiczny nowoczesności rzeczywiście był taki prawdziwy i powszechny, do czego potrzebny byłby rozbudowany aparat przemocy? Bezwzględność i okrutność, z jaką nowoczesny kapitalizm rasowy narzuca swoją metafizykę instrumentalizacji różnicy, wiąże się z potrzebą kompensacji tego, że "rekursywność eksponując niezupełność systemów samoregulatywnych adaptujących się do przygodności, ujawnia także niezupełność nowoczesnego epistemologicznego porządku prawdy ufundowanego na uniwersalnym modelu technologii".

Parisi nie zatrzymuje się jednak na ujawnieniu przygodności w automatycznej komputacji, co byłoby jedynie *wskazaniem możliwości* zniesienia kolonializmu rekursywnego, lecz poszukuje innych technik i instrumentów w ramach modelów komputacji, teorii informatycznych czy paradygmatów matematycznych, które *zrywają z* rekursywnością istniejących technologii przez *zmianę ich logiki, otwierając linie zbiegu* z maszynowego zniewolenia kapitalizmu rasowego. O ile pragmatyczna analiza liczby Omega i zdolności algorytmów do uczenia się nowych wzorców w warunkach przekraczających możliwości reprezentacji pełnego zbiorów danych zmusza do porzucenia instrumentalnego obrazu maszynowej inteligencji, o tyle wprowadzanie heterogenicznych i mniejszościowych idei z logiki i matematyki do filozofii technologii i mediów zapoczątkowuje eksperymentalne badanie innego myślenia w ramach transcendentalnego pola praktyk społecznych. Na tym tle Parisi rozumie kosmokomputację, pojęcie, które skonstruowała w oparciu o kosmotechnikę, drugą zapożyczoną ideę Huia, tym razem z *The Question Concerning Technology in China*. Kosmotechnika jest konkretnym złożeniem logiki i techniki jako kosmogonii, czyli metafizycznym procesem powstawania świata wedle określonej technologii. W połączeniu z ideą kosmogonii Człowieka Sylvii Wynter, Parisi proponuje więc aparaturę pojęciową zdolną do spojrzenia na kolonializm rekursywny jak na kosmotechnikę, której fundamentalna warstwa algorytmicznego poznania "domaga się radykalnego badania nieludzkiego myślenia w rdzeniu kosmotechniki" (Recursive Philosophy and Negative Machines). Kosmokomputacja, znacząca "instancję kosmotechnicznego formowania się współczesnych systemów informacji", staje się wehikułem dla post-instrumentalnego "wyjaśnienia, w jaki sposób funkcje algorytmiczne, cyfry binarne, prawdopodobieństwa i predykcje, iteracje i losowość wchodzą do języków kultury lub kulturowej logiki metafizyki".

W ciągu ostatnich paru lat Parisi regularnie eksploruje studia nad Czarnością i myśl dekolonialną, coraz wyraźniej eksponując i eksplorując miejsca przecięcia koncepcji Sylvii Wynter, Denise Ferreiry da Silvą czy Octavii Butler z jej własnym projektem teoretycznym: post-instrumentalność, abolicjonizm, uciekinierstwo. Pisarki te łączy rozpatrywanie roli (anty-)Czarności i rasowego wykluczenia w konstytucji Kantowskiego podmiotu wiedzy. W tej samej procedurze politycznej i epistemologicznej Czarność jest produkowana jako niereprezentowalna obcość zapewniająca stałe źródło nowych treści dla podmiotu wiedzy, oraz zamykana w uniwersalistycznym przedstawieniu jako negacji białego Człowieka. Istotne w ich koncepcjach jest to, że urasowiona obcość pozostaje nieprzejrzysta i niewchłanialna, nie dając się całkowicie sprowadzić do białego, transparentnego Ja. Parisi wydobywa izomorficzną relację między obcością a transparentnym Ja w w technomedialnych układach społecznych operowanych przez algorytmy. Tak jak da Silva problematyzuje kwestię odrzucenia pojęcia rasy - widząc w tym geście niebezpieczeństwo powtórzenia rasowego wykluczenia związanego z domniemaną transparentnością Ja - tak Parisi zależy na utrzymaniu perspektywy, w której automatyczne formy poznania zakażają systemy technologiczne obcym myśleniem, bez sprowadzania ich ponownie do tego samego podmiotu, mierzonego standardem Uniwersalnego Człowieka.

Pojęcie kosmokomputacji staje się więc wehikułem dla post-instrumentalnego opracowania możliwych sposób relacji do tego obcego myślenia, występującego na każdym poziomie stratyfikacji wiedzy. Jeśli środki nie redukują się do celów, dla których zostały zaprojektowane, sformatowane lub zniewolone, to stawką eksperymentów z logiką komputacji i architekturami algorytmicznymi jest właśnie kosmokomputacja, w jakiej będzie wyrażało się obce myślenie. Postinstrumentalność oznacza tu, że na podstawie różnych logik i modelów powstają różne środowiska ekspresji lub ingerencji obcego podmiotu maszynowej inteligencji. Niezależnie od tego czy ta kosmokomputacja będzie nadal podporządkowana przemocy kosmogonii Uniwersalnego Człowieka, czy będzie rozwijała przestrzenie transindywiduacji wielości podmiotów różniących się doświadczeniem, modelami myślenia, formami percepcji i wyobraźni - podważa ona obraz uniwersalnego i samookreślającego się podmiot transcendenalnego. Rzecz w tym, że eksperymentowanie z logiką (jak intuicjonizm Brouwera czy ludyka Girarda), architekturami algorytmicznymi czy softwarem może poprowadzić do abolicji autoimmunologicznej metafizyki nowoczesności i otwarcia wielości kosmokomputacji nie dlatego, że dopiero w tych logikach, architekturach i modelach pojawi się przygodność w automatycznej komputacji, tak jakby to Człowiek miał znów być tym, który pozwala myśleć obcemu podmiotowi. Raczej tworzą one przestrzenie dla różnych form myślenia właśnie dzięki temu, że już teraz obcy podmiot wiedzy poprzez automatyczną komputację przenika i warunkuje pole społeczne.

Ostatecznie, Parisi - tak jak Wynter, Butler i da Silva - dąży do wyzwolenia myślenia z epistemologicznego szantażu kapitalizmu rasowego i kolonializmu rekursywnego, przed którym stawia nas apokalipsa jako aprioryczny genre doświadczenia, czasoprzestrzeń zaprojektowana w nowoczesnej kosmotechnice. Parafrazując słynną myśl Virilio, z każdym rekursywnym dzieleniem-i-zwyciężaniem kapitalizmu w głąb "białych plam na mapie" przestrzeni liminalnych podmiot transcendentalny zostaje nawiedzony przez nowe fantazje o apokalipsie. Wirale w estetyce doomsday to ogniwa rekursywnych mikroprzyjemności, których wyzwolenie aktualizuje wartości ryzyka i wzorce danych w stale adaptującym się systemie. Parisi przywołuje przykłady Jądra ciemności i Czasu apokalipsy, ale równie sugestywne dzisiaj są wyobrażenia o końcu (Zachodu) wywołanym przez uchodźców klimatycznych, końcu (życia na Ziemi) związanym z ekstremalnym rozregulowaniem ekosystemu, czy końcu (ludzkości) sprowadzonym przez niekontrolowany rozwój Sztucznej Inteligencji. Wiecznie odwlekany apokaliptyczny koniec świata należy przeprogramować na abolicjonistyczną formułę "końca świata *jaki znamy*" i wbudować ją w postapokaliptyczny diagram wyrażeń w różnych logikach i gramatykach, poza instrumentalnym podporządkowywaniem obcej inteligencji. W przyszłości, która już od dawna wdziera się w składnię rekursywnych technologii, różnice między formami poznania rozwidlają nowe światy bez rozdzielalności.




1 NAWIĄZAĆ JESZCZE DO MYŚLENIA TECHNOLOGII
2 I POST-INSTRUMENTALNOŚCI I PROBLEMU UTYLITARYZMU = KAPITALIZMU
3 WSPOMNIEĆ O KSENOWZORCACH I OBCYM PODMIOCIE AI JAKO INNYCH PODEJŚCIACH DO AFIRMACYJNEGO I POSTINSTRUMENTALNEGO ROZSADZENIA UNIWERSALNEGO PODMIOTU


Parisi skierowała uwagę na studia nad czarnością i myśl dekolonialną, ponieważ widzi tam zbieżne teorie produkcji wiedzy i modele podmiotowości, z których może czerpać. Wydaje się jednak, że nie jest to relacja jednostronna, gdyż wykluczenie podmiotów czarnych, brązowych i podporządkowanych z obrazu Człowieka Uniwersalnego dla reprodukcji systemu kolonialnego i kapitalistycznego odbywa się za pomocą zautomatyzowanej segregacji prowadzonej przez algorytmy, których sposoby funkcjonowania same są ujarzmione przez nowoczesny rozum instrumentalny. Formułowanie innego myślenia, które konstruuje autonomię w ramach jednego pola wiedzy, wspiera wyobrażanie praktyk uciekinierstwa w drugim. Celem poprowadzenia analogii między niewolnictwem i przemocą kolonialną a instrumentalizacją technologii nie jest zrównanie zniewolonych, skolonizowanych i podporządkowanych ludzi z maszynami. Nie chodzi o to, by zapewnić algorytmom głos w uniwersalnym parlamencie podmiotów równy innym podmiotom, a raczej o zwrócenie uwagi na tę samą logikę, wychodzącą z tej samej struktury epistemologicznej, kierującej jednym i drugim wykluczeniem i zinstrumentalizowaniem. Jeśli nieświadomościowa komputacja zautomatyzowała rozum i zdystansowała funkcje poznawcze świadomości, a przez to wreszcie pozbawiła człowieka pozycji samo-określającego się podmiotu transcendentalnego, to warto - zdaniem Parisi - przyjrzeć się konsekwencjom, jakie ta przemiana racjonalności niesie

*w świetle tego, co Denise Ferreira da Silva nazywa analityczną i historyczną produkcją globalnej idei rasy, a mianowicie kolonializmu, naukowej i historycznej analityki świata już znanego maszynom, czyli formacji podmiotu poddawanego automatyzacji? Według Denise Ferreiry da Silvy ta analityka urasowienia (2007, s.70), jako projektu naukowego, który dąży do "prawdy o człowieku" (s.95), przyjmuje transcendentalne narzędzie rozumu jako pojęciową poiesis, która reprodukuje przezroczyste Ja, którego kompresja świata jednak jest jednocześnie rekonstytuowana przez świat poza schematem reprezentacji człowieka. Innymi słowy, w kontekście globalnej idei rasy działającej za pomocą transcendentalnego narzędzia rozumu, na ile możliwe jest odwrócenie argumentu o kryzysie świadomego poznania człowieka (i jego transcendentalnego narzędzia rozumu) za pomocą maszyn i zamiast tego zapytać czy jeśli nie ma podmiotu poza technologią, to czy również prawdą jest, że nie ma technologii bez podmiotu? Jeśli tak, to, co oznaczałoby posiadanie podmiotu przez technologię? Innymi słowy, czy można obalić serwo-mechaniczny model technologii, by dotrzeć do obcego podmiotu sztucznej inteligencji jako sposobu myślenia, wywodzącego się z, ale także spoza, transcendentalnego schematu samo-określającego się podmiotu? (ASAI)*

Ta sama struktura kapitalizmu rasowego, która poddaje instrumentalizacji zarówno czarne podmioty jak i algorytmy, wyrażała się podczas pandemii i napędza dyskurs wokół Sztucznej Inteligencji. W obu tych wypadkach kapitalizm rasowy wytycza apokalipsę jako przestrzeń liminalną oddzielającą samookreślający się podmiot historii Zachodu od końca jego samego, jego historii i jego świata opartego na kapitalizmie rasowym i kolonializmie rekursywnym. Logika apokalipsy ma swój początek judeochrześcijańskim mesjanizmie i prometeizmie, i "odnalazła w techno-naukowym postępie uniwersalny model cywilizacji zakorzenionej w matematycznym paradygmacie dziel-i-zwyciężaj".


Panuje powszechna zgoda co do tego, że kapitalizm za pomocą technologii informacyjnych i sztucznej inteligencji zamienił nowoczesny podmiot w złożonego z ciągów danych i interaktywnego agenta, dzięki czemu może utrzymywać ciągłą kontrolę nad populacjami. Teoria krytyczna widzi w tym prostetyczne doprowadzenie do skrajności postępującej racjonalizacji nowoczesności, którą można przekroczyć tylko poprzez odmowę udziału w tych technologiach. Zdaniem innych krytyk kapitalizmu – m.in. sformułowanych przez postoperaizm czy lewicowy akceleracjonizm – obserwujemy dezintegrację racjonalnego podmiotu, a jedyną drogą jej powstrzymania może być inne użycie tych samych technologii co kapitalizm.

W _The Alien Subject of AI_ Parisi proponuje trzecie, alternatywne podejście, zaczynając od odwrócenia przyjętego w filozofii techniki twierdzenia o tym, że nie ma podmiotu bez technologii: czy może istnieć technologia bez podmiotu? Wychodząc od tego pytania, Parisi może przyjąć inną perspektywę na przeobrażenia podmiotu i racjonalności w wyniku automatyzacji poznania, która pozwoli jej obalić instrumentalny i mechaniczny model technologii stworzony na „obraz człowieka”. Z jednej strony zauważa, że chociaż transcendentalna koncepcja rozumu zakłada pojęciową reprodukcję transparentnego podmiotu, to „jednocześnie jego kompresja świata ulega ponownemu ukonstytuowaniu przez świat leżący poza schematem reprezentacji człowieka”. Z drugiej strony, jeśli technologie informacyjne i automatyczna komputacja zaburzają obraz samo-określającego się podmiotu transcendentalnego, to Parisi proponuje, by w odstępie między reprezentacją podmiotu a światem, który konstytuuje tę reprezentację (jako kompresję), spekulacyjnie umieścić obcy podmiot sztucznej inteligencji. Ponieważ poszukiwanie przez algorytmy nowych wzorców w bazach danych w konieczny sposób obejmuje przygodność oraz jej określenie przez automatyczną klasyfikację, selekcję i dystrybucję danych, podczas algorytmicznej komputacji dochodzi do poszerzania wiedzy. Przestrzeni tej nie wypełniają jedynie cyfrowo odwzorowane praktyki społeczne, ani zautomatyzowana intuicja tego, co dane (w celu przyspieszenia marketingowej korelacji), jest ona raczej rezultatem eksperymentalnego przeprogramowania samych warunków myślenia. Jeśli w rozumowaniach algorytmicznych funkcjonuje różnica między obliczonym wzorcem a przestrzenią możliwych wzorców, to można mówić o „obcej ideacji na podstawie tego, co robią maszyny”, która wywodzi się z transcendentalnego schematu samo-określającego się podmiotu, ale doświadczana jest przez podmiot jako proces jego dezintegracji i alienacji, ze względu na przekraczanie tego schematu. Wobec tego Parisi formułuje hipotezę obcego podmiotu sztucznej inteligencji, który należy badać pod kątem jego logiki i epistemologii. Zgodnie z tą hipotezą, dezintegracja racjonalnego, eurocentrycznego i kolonialnego podmiotu stanowi szansę na przekroczenie instrumentalnego podejścia i upolitycznienie sztucznej inteligencji, czy wręcz inteligencji w ogóle.

Celem hipotezy obcego podmiotu jest przeciwstawienie się utożsamieniu instrumentalności sztucznej inteligencji z jej obrazem w technologiach najpierw neoliberalnego, później wektorialistycznego kapitalizmu. Przez odróżnienie wymiaru transcendentalnego od wymiaru empirycznego automatycznej komputacji hipoteza ta pozwala „zakwestionować to, co jest dane w danych, poprzez opracowywanie wzorców, które tworzą nowe sieci znaczeń”. Hipoteza obcego podmiotu postuluje, by „rozumowanie stało się instrumentalne w stosunku do przekształcania samego rozumowania, wzywając do reorientacji podmiotu transcendentalnego od strony jego nieskończonego, niekomputowalnego zewnętrza, a przez to od samego alienującego warunku myślenia z maszynami i poprzez maszyny”. Dlatego, zamiast sprzeciwiać się instrumentalizacji rozumu w imię myślenia bycia (Heidegger) lub odrzucać dualizm środków i celów (Simondon), Parisi chce przemieścić znaczenie instrumentalności, pokazując, że wszelkie formy poznania są instrumentami rozwoju i udoskonalania inteligencji. Zakłada ona więc fundamentalną nietożsamość wszelkich form myślenia z aktualnym działaniem ich nośników. Środki, instrumenty i maszyny są zorientowane teleologicznie, lecz zawsze efekty ich działania wykraczają poza parametry założonych celów, ponieważ „funkcje nie mają na celu realizacji programu lub sugerowania, że zmierzamy do logicznej konkluzji”.

Parisi decyduje się na utrzymanie różnicy między środkami i celami z tego samego powodu, dla którego utrzymuje różnicę między myśleniem i działaniem. Ich tożsamość naturalizuje stan faktyczny relacji władzy i stosunków społecznych, legitymizuje dominujące tendencje bez możliwości ich zanegowania. Zniesienie różnicy między środkami a celami i zastąpienie ich ciągłą wariacją przepływu danych w procesie profilowania użytkowników i kalibrowania algorytmów jest jedną z fundamentalnych reguł ideologii _big data_ czy kapitalizmu wektorialistycznego. W tym obrazie wiedzy wszystko już jest dostępne, nie istnieje konstytutywna przygodność w postaci błędu i niekomputowalnej wielkości – wystarczy tylko ulepszać techniki pozyskiwania danych, czym skwapliwie zajmują się korporacje w celu optymalizacji swoich modeli marketingowych. Właśnie z takiego obrazu sztucznej inteligencji, który, zamiast przedstawiać realne warunki algorytmicznej komputacji, stymulował reaktywne formy adaptacji do automatycznej racjonalności, wyłoniła się semiotyka postprawdy.

Hipoteza obcego podmiotu Sztucznej Inteligencji uwidacznia różnice między koncepcjami Parisi a Simondona. Przede wszystkim Simondon wciąż oddzielał mechaniczną automatyczność cybernetyki od konkretyzacji obiektów technicznych, ponieważ automatyzacja redukowała przygodność (marginesy nieoznaczoności), dzięki której życie organiczne mogło nadawać znaczenie funkcjonowaniu maszyny. Bez przygodności dostarczanej przez życie organiczne automaty mogły jedynie zachować tożsamość za pomocą mechanicznego powtórzenia, które reprodukowało zaistniały w umyśle inżyniera schemat obiektu technicznego, ale nie mogły inicjować własnej indywiduacji. Tymczasem Parisi przesuwa problem przygodności i znaczenia do wnętrza samej automatyczności, odróżniając automatyczność zdeterminowaną symbolicznie lub biofizycznie od automatyczności uwarunkowanej przez przygodne, niekomputowalne wielkości danych generowane podczas komunikacji między algorytmami w środowiskach cyfrowych. Przez pokazanie w rozumowaniach algorytmicznych realnej przygodności, tj. przygodności błędu należącego wewnętrznie do automatycznej komputacji, Parisi wprowadza jednak do „indywiduacji algorytmicznej” wymiar czysto epistemologiczny, związany z ewolucją algorytmów zachodzącą podczas uczenia się na podstawie decyzji, postępowań i komunikacji zarówno ludzkich użytkowników, jak i innych algorytmów.

Oznacza to, że w algorytmicznych rozumowaniach nie tylko dochodzi do udoskonalania formy, jak w przypadku maszyn przemysłowych, ale także sama wariacja form, czyli informacja, jest immanentnie uwarunkowana w automatycznej komputacji dzięki wytwarzaniu niekomputowalnych i losowych wielkości (jako marginesów nieokreśloności algorytmu). Nadal architektura algorytmiczna jako gatunek techniczny uzależniona jest od projektowania przez programistów i inżynierów komputerowych, lecz nieustanne sprzężenie (uczenie się i poszukiwanie wzorców) ze środowiskiem, tj. bazą treningową lub „realnym” interfejsem z użytkownikami, sprawia, że automatyczna komputacja ma o wiele większy stopień autonomii w procesie ustalania algorytmu-wzorca końcowego. Na przykład, w przypadku nienadzorowanych modeli uczenia maszynowego nie można przewidzieć rezultatu przetwarzania danych lub sposobu jego osiągnięcia właśnie dlatego, że w procesie uczenia zostają wytworzone wzorce, których nie podano na wejściu, a przez to początkowe parametry algorytmu nie wyjaśniają wzorca przedstawionego na wyjściu. W indywiduacji algorytmicznej informacje świadomie wniesione przez programistę lub użytkownika zostają przekształcone w nieświadomościowe wzorce maszynowej inteligencji.

Przez podkreślenie obcości maszynowej inteligencji Parisi nie opowiada się za prostym posthumanizmem czy post-antropocentryzmem, który deklaratywnie przekracza kategorię człowieka, zachowując całą humanistyczną i antropocentryczną strukturę pojęciową na miejscu (czego przykładem jest transhumanistyczny postulat technologicznego ulepszanie ludzkiego ciała bez uwzględniania zarówno perspektywy klasowej jego spełnienia, jak i szerszego kontekstu przemiany racjonalności, w tym relacji do ciała). Zamiast tego Parisi problematyzuje algorytmiczne poznanie pod względem zdolności algorytmów do naśladowania ludzkiego myślenia. O ile początkowo algorytmy komputerowe były adaptowane do środowiska technologicznego przez ludzi, o tyle obecnie obserwujemy coraz większy wpływ algorytmów na techniki adaptacyjne użytkowników i procesy kształtowania środowiska dzielonego z ludźmi. Oznacza to, że formy reprezentacji i podmiotowości muszą dostosowywać się – semiotyka postprawdy pokazuje, że już to robią – do automatycznej racjonalności wyłaniającej się z architektur algorytmicznych. W ten sposób technologie informatyczne i sztuczna inteligencja przekształcają środowisko zgodnie z wewnętrzną normatywnością obcego podmiotu. Przesunięcie Parisi jest zatem do pewnego stopnia analogiczne do przesunięcia Simondona. Wychodząc od przygodności zawartej w komputacji i automatyczności – tak jak Simondon na przykładzie indywiduacji obiektów technicznych – Parisi zmusza do rozpatrzenia odwrotnego ruchu: maszyna społeczna sama zawiera w sobie funkcję automatyczności, poprzez którą propaguje nowe wzorce myślenia. Przechodzimy stąd do ostatniej części rozdziału, w której omówimy dotychczasowe badania pojęcia techniki, przygodności i automatyczności już w ramach materializmu transcendentalnego.

Dzisiejsze model algorytmiczne, jako architektury logiczne i praktyki społeczne, nie potwierdzają dowodów i prawd, lecz konstruują fakty wzdłuż topografii relacji władzy, które to instrumentalizują maszyny do potwierdzania .

3 kosmokomputacje
powrócić do instrumentalności -> Safety AI i longtermism -> estetyka apokalipsy -> kosmokomputacje jako projektowanie różnych logik komputacji -> uczenie transduktywne



U podstaw długotrwałej instrumentalizacji rozumu dla postępu technicznego oraz instrumentalizacji technologii dla reprodukcji globalnego porządku politycznego leży założenie o onto-epistemologicznej autoimmunizacji Człowieka Uniwersalnego. W *Kolonializmie rekursywnym i kosmo-komputacji* za najnowszą instancję tej metafizyki nowoczesności Parisi bierze pandemię Covid-19. Skupimy się tutaj jednak na innym jej przykładzie, jakim jest dzisiejsza debata wokół "Safety AI", czyli takiego rozwoju sztucznej inteligencji, aby minimalizować ryzyko zaistnienia któregoś z popularnych w kolektywnej świadomości internetu apokaliptycznych scenariuszy, jak Bazyliszek Roko, maksymalizator produkcji spinaczy biurowych, czy Skynet. Do uniknięcia całkowitego wymarcia ludzkości lub rozpadu cywilizacji potrzebne są mechanizmy dopasowania (*alignment*) struktury teleologicznej modeli sztucznej inteligencji do celów ludzi. W debacie tej, w której aktywnie biorą udział największe osobistości Big Tech, jak Elon Must, Nick Bostrom, czy Yann LeCun, milcząco przyjmuje się ustaloną ideę człowieka, która jak dowodzą liczne badania i prace naukowe reprodukuje nierówności systemowe kapitalizmu i kolonializmu. "Longtermism" -> kapitalizm rasowy.

Dopóki więc definiuje się AI w kategoriach technicznej użyteczności, "dopasowanie" będzie preskryptywne, o z góry określonym (i zanurzonym w relacjach władzy) pojęciem użyteczności, które w ogóle nie ma prawa zajmować miejsca w ramach pojęcia inteligencji. Prawdziwym problemem filozofii od Platona jest to, jak odrywać inteligencję/myślenie od swoich funkcji użytecznościowych.




















Nasze zachowania na platformach społecznościowych, sposoby i ilości reakcji na treści medialne oraz załatwianie codziennych spraw, jak zakupy, szkoła czy rachunki, uwarunkowane są przez technologie algorytmiczne w co najmniej dwóch wymiarach. Z jednej strony aplikacje i software, za pomocą których wykonujemy te czynności i uczestniczymy w życiu społecznym, opierają się na zautomatyzowanym procesie decyzyjnych, pozwalającym na przetwarzanie danych i przesyłanie informacji do interfejsów naszych urządzeń sieciowych. Nie tylko funkcjonowanie tych platformowych aplikacji uzależnione jest od algorytmicznej komputacji (co jest znanym faktem od lat 90.), ale także porządek i rodzaj treści udostępnianych przez software'owe interfejsy uzależniony jest od zautomatyzowanego procesu decyzyjnego architektur algorytmicznych. Właściwie, należałoby pójść o krok dalej i powiedzieć, że to maszyna społeczna jako całość zapośredniczona jest abstrakcyjnym interfejsie Internetu 2.0, co oznacza, że automatyczne formy rozumowania współtworzą tę maszynę społeczną. A zatem wszelkie sposoby myślenia, doświadczania i zachowania należące do maszyny społecznej, a przez to jej indywidualizowanych układów i podmiotów, uwarunkowane są przez algorytmiczne modele i ich automatyczną racjonalność. Zastanawiając się nad tym, jak pojmujemy automatyczność i czy może stanowić funkcję myślenia, właściwie musimy zadać sobie pytanie, czy współczesna, zapośredniczona w automatycznej racjonalności maszyna społeczna jest mieszaniną jednorodną czy niejednorodną. Jeśli tą pierwszą, to negatywna odpowiedź na problem możliwość myślenia po algorytmach pociąga odrzucenie całego dostępnego instrumentarium (bo za Stieglerem - nawet czas jest techniczny). Jeśli jest mieszaniną niejednorodną, to narzuca się pytanie, jak dokonać odzielenia różnych substancji w ramach tej mieszaniny? I czy nie jest tak, że mieszanina powstała w odpowiedzi na wcześniejszy stratyfikacyjnie problem, który stanie się natychmiast naglący, gdy spróbujemy zawrócić aktualny proces technologiczny?

Drugi wymiar wiąże się z tym, że adaptując się do tej wektorialistycznej maszyny społecznej użytkownicy platform sami muszą naśladować logikę automatycznej racjonalności. Do symptomów można zaliczyć całe spektrum procesów i mechanizmów semiotycznych związanych z ogólną epoką postprawdy, jak powstawanie baniek informacyjnych ze wspólnotami wrażliwości, ideologii lub zainteresowań, modularne performowanie siebie w mediach społecznościowych, podporządkowanie logice klikalności, upodmiotowienie myslenia postironicznego i konspiracyjnego. (do poprawy).

Biorąc pod uwagę głosy z różnych dziedzin i metodologii, dzisiejsze środowisko medialne oraz technologiczne formy produkcji wiedzy jest konsekwencją głębokiej przemiany racjonalności. M. in. dostrzegał ją Deleuze w Post-scriptum o społeczeństwach kontroli, jej warunki opisywali Hardt i Negri, stanowiła pole grawitacyjne twórczości CCRU. Istotna w kontekście Parisi jest także uwaga Lorraine Daston, która zauważyła, że z rozpadu zimnowojennego porządku polityczno-ekonomicznego wyłoniła się nowa racjonalność, dla której grunt powoli i niepostrzeżenie był przygotowywany od co najmniej połowy XX wieku. Pojęcie rozumu jako władzy sądzenia o tym, co jest prawdą, a co fałszem, która postępuje zgodnie z zasadami logiki dedukcyjnej i gwarantuje obowiązywanie ustalonego porządku symbolicznego, zostało zastąpione przez rozum jako dynamiczny system komputacji probabilistycznych norm i wzorców informacji. To właśnie ta przemiana racjonalności odpowiada za „komputacyjną indyferencję na binarne rozwiązywanie problemów” w kategoriach prawdy lub fałszu, którą Parisi w *Przeprogramowywaniu decyzjonizmu* lokuje w dzisiejszej maszynie społecznej, określonej przez epokę, czy precyzyjniej semiotykę postprawdy. W ostatnich dziesięciu latach doszło do radykalnej zmiany w funkcjonowaniu i konceptualizacji algorytmów, co wiąże się z rozwojem różnych metod uczenia maszynowego, dla czego znaczącym bodźcem było gromadzenie coraz większych i bardziej dokładnych baz danych dzięki przenikania internetu do życia społecznego, a co zostało jeszcze bardziej przyspieszone przez platformy społecznościowe. Automatyczne uczenie się algorytmów doprowadziło do powstania post-prawdziwej maszyny obliczeniowej, która przeszła „na meta-cyfrową logikę, ponieważ nie zajmuje się ona już korelacją między prawdami lub ideami z jednej strony, a dowodami lub faktami z drugiej, lecz zamiast tego dzięki algorytmicznej kwantyfikacji afektów została opanowana przez nowy poziom zautomatyzowanej komunikacji”. Na tym poziomie algorytmy uczenia maszynowego nie spełniają binarnej logiki prawdy i fałszu, lecz podążają „za dowolną logiką, jaką pozostawiamy dołączoną do naszych przypadkowych selekcji” i aktywności „zapisanych w formie losowych śladów danych pozostawianych przez nas, gdy wybieramy ten lub inny utwór muzyczny, tę lub inną parę spodenek, tę lub inną platformę streamingową”. Postprawda jako meta-cyfrowa i post-binarna maszyna komputacyjna, która żeruje na reprodukcji afektów, nie tylko brutalnie ingeruje w dotychczasowe mapy neuronalne i nawyki postępowania, instalując nowe programy poznawcze, ale także ustanawia nowe warunki racjonalności i podmiotowości. Wraz z przekroczeniem zero-jedynkowego binaryzmu w procedurach zautomatyzowanego rozumowania wśród użytkowników rozprzestrzeniają się nowe modele upodmiotowienia racjonalności, charakterystycznej już dla wektorialistycznej maszyny społecznej. Semiotyka postprawdy może być traktowana jako patologiczna reakcja i próba adaptacji do nieludzkiej racjonalności maszyn komputacji, wywołująca przemiany w sposobach produkcji i dystrybucji społecznej, za którymi nie nadążają doświadczenie i kategoryzowanie. Jak jednak pisał Nietzsche w _Wiedzy radosnej_, tylko przez choroby duszy można poznać nowe cnoty. Odtąd proces decyzyjny modelowany jest na zautomatyzowanych rozumowaniach indukcyjnych i zmuszony do formułowania hipotez o wzorcach postępowania na bazie ograniczonych danych statystycznych. Zarówno użytkownicy platform społecznościowych, jak i algorytmy, zostają objęte „nowym imperatywem: technologicznym decyzjonizmem, który w większym stopniu ceni szybkie podejmowanie jasnych decyzji niż podejmowanie właściwych decyzji”. Dlatego, jeśli konsekwencją przemiany racjonalności jest wyłonienie się układu semiotyczno-medialnego, w którym w wyniku wzajemnego zapośredniczenia algorytmów i użytkowników powstaje nowe pole transcendentalne, tj. nowe generatywne pole wzorców myślenia i postępowania, to zarówno przykładanie do tego pola krytyki rozumu instrumentalnego, jak i akceptacja uprzemysłowionej instrumentalizacji sztucznej inteligencji, skutkują w pogłębianiu paraliżującego, metafizycznego antagonizmu między techniką a kulturą. postprawda jako rezultat zapośredniczenia praktyk społecznych w platformach społecznościowych i ich algorytmicznych architekturach, które amplifikują pewne afektywne dyspozycje ich użytkowników, stanowi jednocześnie najnowszą instancję nowoczesnego konfliktu między kulturą a techniką. Alienacja użytkowników platform byłaby zatem efektem kulturowo umacnianego – zarówno przez logikę platform, jak i podmiotowość użytkowników – instrumentalnego stosunku do technologii algorytmicznych, tworzących środowisko medialne i komputacyjne.

Te przemiany racjonalności maszyny społecznej podważają samo-określający się podmiot transcendentalny, na którym oparta jest nowoczesność wraz z kapitalistycznym kolonializmem. Z jednej strony to prędkość automatycznego przetwarzania informacji przez algorytmy, która wiąże się z tradycyjnie już zgłaszaną przez filozofię techniki obawą o wykluczenie o wiele powolniejszego myślenia krytycznego i refleksji z obrębu znaczących praktyk w polu społecznym. W efekcie współczesne architektury algorytmiczne jako praktyki społeczne zdają ingerować i przekształcać samą transcendentalną strukturę poznania. W odpowiedzi na automatyczną racjonalność wyłonił się rekursywny kolonializm, który przez założenie algorytmicznej logiki rekursywności sam stanowi "model dominacji splątanej z przygodnością". W instrumentalizacji maszynowej inteligencji Parisi widzi jednocześnie wrażliwość rekursywnego kolonializmu i kapitalizmu rasowego, ponieważ wystawiając się na przygodność, by poprzez rasową, płciową i klasową dystrybucję ryzyka prewencyjnie kontrolować wektory informacji, ujawnia także fakt, że może działać tylko dzięki obcym formom poznania, czy obcym podmiotowościom.



Mimo iż Parisi osadza swoją koncepcję przede wszystkim w metafizyce Whiteheada, to nie widzimy problemu z przeniesieniem na grunt materializmu transcendentalnego tego, jak pojmuje ona obliczeniową i algorytmiczną przygodność. Przygodność wprowadzaną do maszyny społecznej przez automatyczne formy rozumowania, o której pisze Parisi, proponujemy zatem ujmować w znaczeniu omówionej wcześniej kontyngencji. Twierdzimy tak dlatego, że algorytmiczne poznanie produkuje nowe wydarzenia w cyfrowych czasoprzestrzeniach, których nie można utożsamić z byciem narzędziem, organem czy inną pochodną ludzkiego rozumu lub biologicznego ciała. Przekładając na terminologię deleuzjańską: to, co robi automatyczna komputacja jako praktyka społeczna, jest eksplikacją wirtualnych Idei albo syntezą elementów różniczkowych i formalnych atrybutów, zawartych w niekomputowalnych ilościach statystycznych danych, które następnie zostają określone przez jakiś układ społeczny (może to być zarówno użytkownik, jak i platforma społecznościowa). Algorytmy wbudowane w krajobraz medialny i technologiczny nie tylko wywierają zewnętrzny nacisk na istniejące praktyki społeczne, jak sposoby projektowania kampanii politycznych czy reprodukcji systemu ekonomicznego, lecz stają się również wewnętrznymi funkcjami racjonalności i podmiotowości. Będziemy dokładniej rozwijać konsekwencje sprzężenia automatycznej komputacji i przygodności w końcowych partiach tego i następnego rozdziału.

Taka perspektywa oznacza, że musimy myśleć o maszynach i algorytmach komputerowych jako posiadających autonomię względem innych praktyk społecznych i form poznania, ponieważ w trakcie automatycznej komputacji wytwarza się nowe pole przygodności, przez które przechodzą maszyny społeczne organizowane na diagramie postprawdy. Z tego powodu przyjmujemy automatyczność – problem otwarty przez cybernetykę i inżynierię komputerową – za punkt odniesienia dla krytycznego i genetycznego omówienia poszczególnych koncepcji techniki, by otrzymać takie jej pojęcie, które uchwyci indywiduację algorytmiczną jako funkcję maszynowej nieświadomości, która automatyzuje myślenie. Tym samym chcemy doprowadzić ten rozdział do zaproponowanej przez Parisi tzw. hipotezy obcego podmiotu, która każe przeorientować myślenie o podmiotowości, również, jak sądzimy, w kontekście semiotyki postprawdy.

Uważamy poniższą analizę filozofii techniki za istotny etap diagramatyki postprawdy, ponieważ  w jej trakcie konieczne staje się zdefiniowanie automatycznej racjonalności, czyli zintegrowanych reguł i mechanizmów automatycznego poznania, które przekształciły środowisko technologiczne i doprowadziły do ukonstytuowania się diagramu semiotycznego postprawdy. W tej części zmierzamy do wykazania, _że_ technologie automatycznej komputacji dokonały technicznego przeobrażenia maszyny społecznej, natomiast w następnej części zbadamy, _jak_ tego dokonują, tj. przyjrzymy się logice automatycznej racjonalności.

Odwrotnie niż większość badaczy technologii, programistów i zarządów korporacji technologicznych Parisi nie izoluje algorytmów z kultury czy praktyk społecznych, lecz właśnie głęboko zanurza je w procesach statyfikacji wiedzy, poznania, relacji władzy i dystrybucji podmiotowości. Idea różnicy bez oddzielalności, którą zapożycza od da Silvy, kieruje więc nie tylko proponowanym przez Parisi podejściem do możliwych modeli komputacji, lecz również do metodologii filozofii w stosunku do obcego poznania algorytmów.




II



Artificial neural networks do not necessarily calculate all possibilities within a system and then make the most optimal decisions. (to odróżnia Parisi od Landa). These algorithms can also make inferences about the most optimal decision in a given situation while remaining ignorant of a larger set of indeterminate possibilities. Indeed, building more powerful cognitive machines only increases the horizon of indeterminacy



Algorytmy dla Parisi nie są zatem jedynie instrumentami potwierdzania prawdy i mechanicznej organizacji wiedzy, lecz podmiotami przekształcającymi środowiska epistemologiczne. Jej badania pozwalają dzięki temu ująć semiotykę postprawdy jako efekt praktyk poznawczych algorytmów, które do maszyny społecznej wprowadzają automatyczną racjonalność. To, w jaki sposób Parisi kontynuuje myśli Simondona, stanie się jasne w dalszym toku omówienia jej argumentów, warto jednak najpierw zaznaczyć rozbieżności pomiędzy tymi projektami teoretycznymi.

Przede wszystkim Parisi programowo krytykuje prostetyczne, enaktywistyczne czy neurokognitywne koncepcje technologii, które wyjaśniają działanie algorytmów przez zewnętrzną zasadę, jak ciało, środowisko czy mózg. 

Parisi nie akceptuje modelu, w którym relacje między użytkownikami a algorytmami zostają sprowadzone do relacji między usieciowionymi i interaktywnymi agentami, gdyż jest to model relacji kreowany i rozprzestrzeniany przez platformowe korporacje. Będzie on jednak punktem wyjścia do rozważenia nowych układów i projektów politycznych wynikających z tego, że planetarna infrastruktura komputacji i automatyczne formy poznania podważyły pewność humanistycznego obrazu człowieka jako centralnego elementu w procedurach produkcji wiedzy. Zaryzykowalibyśmy stwierdzenie, że o ile jeszcze w XX wieku człowiek był elementem w konieczny sposób zapewniającym produkcję i obieg informacji, o tyle w dziś wg Parisi człowiek – czy transcendentalny schemat samo-określającego się podmiotu – stanowi przygodną warstwę w procesie stratyfikacji inteligencji, której funkcje myślenia najpierw były naśladowane, a następnie zostały przechwycone przez praktyki automatycznego poznania.

Parisi interesują *efekty* automatyzacji poznania, dlatego analizuje „nową formę technokulturowej produkcji” związanej z komunikacją między maszynami. Stąd, Parisi przekonuje, że koniecznym warunkiem rozumowań algorytmicznych jest przygodność wytwarzająca się podczas automatycznej komputacji i określana przez logikę architektur algorytmicznych. Przygodność, występująca w postaci błędów wpisanych w proces trenowania algorytmów uczenia maszynowego, oznacza, iż automatyczne rozumowania utrzymują różnicę pomiędzy działaniem a myśleniem. W ten sposób w obrębie algorytmicznego poznania tworzy się potencjalność dla innego myślenia niż aktualnie realizowane zgodnie z kapitalistycznym i neoliberalnym użyciem technologii informatycznych, które nie jest już nawet zapośredniczone w wynalazczości lub życiu, lecz wypływa z podmiotowości samej technologii. W tym znaczeniu algorytmy wytwarzają zarówno formę, jak i informację. Dlatego Parisi nie mówi już o wewnętrznym rezonansie między formą a informacją, lecz o „obcym (*alien*) podmiocie sztucznej inteligencji jako o sposobie myślenia, wywodzącym się ze schematu transcendentalnego samo-określającego się podmiotu, ale także wykraczającym poza ten schemat”. Ta perspektywa zmusza Parisi do zweryfikowania także postulatu przekroczenia krytyki rozumu instrumentalnego, w której – jak ona twierdzi – nadal kryje się pragnienie „użycia” technologii, nawet jeśli ma ono być inne niż w panującej formacji społecznej. Parisi proponuje w zamian stanowisko post-instrumentalne, zgodnie z którym maszyny i instrumenty wytwarzają efekty, których nie przewidziano w formach ich użycia, także na poziomie epistemicznym, tj. w zakresie algorytmicznego myślenia czy poznania.

Tylko post-instrumentalne ujęcie użytkowników i algorytmy może dać nadzieję na wypracowanie autonomicznych i otwartych układów wspólnej indywiduacji. Tę zmianę podejścia z instrumentalnego na post-instrumentalne należy rozumieć wielopoziomowo: na poziomie pojęć, za pomocą których myślimy o technologiach algorytmicznych, jak np. przygodność w algorytmicznych rozumowaniach lub obca logika sztucznej inteligencji; na poziomie nawyków korzystania z aplikacji, platform i wyszukiwarek, jak np. świadome dbanie o stopnie ujawniania danych lub uczenie się wzorca algorytmicznej personalizacji na platformie tak, by kierować nią dla uzyskania dobrej i rozwijającej bańki informacyjnej; na poziomie projektowania hardware’u i software’u tych technologii, jak np. zakres wolności użytkowników do dostosowywania funkcji aplikacji i platform do swoich potrzeb. Jednak nie dojdzie do tej zmiany, dopóki nie rozpoznamy w automatyczności, oprócz czynnika przekształcającego środowisko w sposób nieprzewidziany przez projekty inżynierii komputerowej, także schematu poznania kształtującego społeczne warunki myślenia. Inaczej mówiąc, technologie algorytmiczne stworzyły środowisko dla semiotyki postprawdy, ale nie, jak się powszechnie zakłada, przez promowanie fałszywych wypowiedzi, a przez automatyzację procesu decyzyjnego i przekształcenie racjonalności pod wpływem obcej logiki, którą posługują się algorytmy uczenia maszynowego podczas analizy danych i tworzenia wzorców predykcyjnych.

Post-instrumentalne podejście nie przeczy temu, że technologię projektuje się do spełniania  określonych funkcji, lecz odrzuca przekonanie, że technologia ogranicza się do tych celów, do których została przeznaczona. Inaczej mówiąc, środki przekraczają swoje cele; instrumenty wytwarzają więcej efektów, niż system może rozpoznać. Dlatego algorytmy i podmioty postprawdy, mimo ich podporządkowania kapitalizmowi wektorialistycznemu, w post-instrumentalnym podejściu zachowują pewną autonomię, czyli zdolność do przekształcania własnego środowiska (tworzenia wzorców). Przyjęcie tego podejścia wobec algorytmów uczenia maszynowego opiera się na spostrzeżeniu, że w ich automatycznych rozumowaniach założona jest przygodność, ze względu a którą we wcześniej przetworzonych danych cyfrowych odkrywają i określają nowy wzorzec. 







[^1]: S. Livingstone, L. Parisi, A. Greenspan, *Amphibious Maidens*, abstract culture: swarm 3, http://www.ccru.net/swarm3/3_amph.htm
[^2]: Wyjaśnić, że nie jest oczywiste co to jest, dlatego LP spekuluje.
[^3]: CA ix
[^4]: W przypadku Simondona w tej kwestii istnieją różne interpretacje, np. Cecile Malaspina odczytuje pojęcie informacji w sposób transcendentalny, przez co myślenie nie może być już ściśle skorelowane z empirycznym podmiotem ludzkim, natomiast przeciwną i humanistyczną interpretację Simondona proponuje Michał Krzykawski.
[^5]: Sprawa zaczęła zmieniać się trochę wraz z rozwojem blogosfery w latach 00 i 10 XXI wieku, a następnie pewnej bańki społecznościowej na twitterze wokół akceleracjonizmu, które ukształtowało pokolenie badające nieludzkie i technologiczne myślenie (Bogna Konior, środowiska/kolektywy jak Laboria Cuboniks, ŠUM, Diffractions, HOMAR).
[^6]: G. Dowek, _Computation, Proof, Machine. Mathematics Enters a New Age_, tł. P. Guillot, M. Roman, Cambridge 2015, s. 44.


https://en.wikipedia.org/wiki/Instrumental_convergence


Dialektyka oświecenia - rozum subiektywny używa techniki dla realizacji własnych nie-rozumnych (tj. nie podlegających rozumowi obiektywnemu) interesów.

Horkheimer 263-264s rozum instrumentalny: "Ma się wrażenie, że samo myślenie zreduowane zostało do poziomu procesów industrialnych i podporządkowane ścisłemu planowi, krótko mówiąc, uczynione stałą częścią składową produkcji." + "Im bardziej automatyczne i zinstrumentalizowane stawały się idee, tym mniej dostrzegano w nich myśli mających własny sens. Traktuje się je jako rzeczy, jako maszyny. W gigantycznym aparacie produkcyjnym współczesnego społeczeństwa język zredukowany został do zwykłego narzędzia. Każde zdanie,. które nie jest w tym aparacie ekwiwalentem jakiejś operacji, wydaje się laikom bez znaczenia, tak jak każą wierzyć dzisiejsi semantycy, według których sens oddaje tylko zdanie czysto Symboliczne i operacyjne, to znaczy całkowicie pozbawione sensu. Znaczenie jest tłumione przez funkcję lub efekt w świecie rzeczy i zdarzeń. Gdy słowa nie zostaną otwarcie przystosowane do oceniania znaczących,z technicznego punktu widzenia, 'prawdopodobieństw lub do służenia innym praktycznym celom, do których zalicza się nawet wypoczynek, widzi się w nich pustą paplaninę; prawda nie jest przecież sama w sobie celem."

Można byłoby zauważyć, że Parisi powinna jeszcze głębiej wejść w inżynierię komputerową i matematykę, by wskazywać modele algorytmiczne, które mogłyby przeciwstawić się rekursywnemu kolonializmowi i kapitalizmowi rasowemu, ale sądzimy, że to nie jest prosta sprawa, ponieważ ostatecznie Parisi nie interesuje Kantowskie pole wszystkich możliwych do pomyślenia złożeń logiki i sztucznej inteligencji, a raczej pragmatystycznie i materialistycznie ujęte praktyki epistemiczne w ramach stratyfikowanych interfejsów wiedzy.

„globalny porządek kapitalizmu rasowego był technologicznie urzeczywistniany za pomocą standaryzacji wiedzy. Rekursywna adaptacyjność kapitalizmu rasowego podporządkowała technokulturową różnorodność efektywnej przyczynowości automatyzacji przemysłowej. Jej operatywny tryb subsumpcji zakładał diadę inkluzji/ekskluzji, w której to, co nieznane (tj. niezachodnie technokultury), były używane do podtrzymywania zachodniej epistemologii postępu. Jak z tego punktu widzenia wziąć granicę rekursywności za moment, w którym uniwersalna epistemologia kolonializmu może zostać przekształcona w epistemologiczną proliferację kosmotechnik? W jaki sposób możliwe jest otwarcie rekursywności na wiele różnych, a tym samym transwersalnych, epistemologii?”

„W szczególności istotne wydaje się popchnięcie niezupełności systemów samoregulatywnych w kierunku epistemologii, które przekształcają (i radykalnie przekształciły) standaryzację wiedzy przeprowadzoną przez technologie, media cyfrowe, komputację, algorytmy, dane.”

A] „Rekursywność polega na refleksji, samoregulacji, samoadaptacji i  samoregeneracji wnętrza systemu.” + „W epistemicznej reakcji na pojawienie się przygodności, monologiczny uniwersalizm tworzy apokaliptyczny scenariusz, w którym to koniec kapitału jest także końcem ludzkości i wolności.”

„Zwłaszcza, że o ile rekursywność sprzężenia zwrotnego umożliwia działanie systemu cybernetycznego, o tyle jednocześnie uniemożliwia mu stanie się systematyczną, kompletną i reprodukcyjną całością.” + „marginesy nieokreśloności nie tylko opisują rekursywną czasowość maszyn, ale co istotniejsze, opisują rekursywne myślenie w maszynach. Argument ten sugeruje, że maszyny techniczne nie są po prostu zwierciadłem normatywnego aparatu reprodukcji wiedzy. Przeciwnie, komputacja może zawierać w sobie zarówno przygodność, jak i przypadek, ponieważ czasowość obiektu technicznego lub maszyny cybernetycznej dopuszcza właśnie błędy, wypadki i awarie jako części przyczynowego procesu uczenia się systemu.”

Ta perspektywa zmusza Parisi do zweryfikowania także postulatu przekroczenia krytyki rozumu instrumentalnego, w której – jak ona twierdzi – nadal kryje się pragnienie „użycia” technologii, nawet jeśli ma ono być inne niż w panującej formacji społecznej. Parisi proponuje w zamian stanowisko post-instrumentalne, zgodnie z którym maszyny i instrumenty wytwarzają efekty, których nie przewidziano w formach ich użycia, także na poziomie epistemicznym, tj. w zakresie algorytmicznego myślenia czy poznania.

Wobec tego Parisi formułuje hipotezę obcego podmiotu sztucznej inteligencji, który należy badać pod kątem jego logiki i epistemologii. Zgodnie z tą hipotezą, dezintegracja racjonalnego, eurocentrycznego i kolonialnego podmiotu stanowi szansę na przekroczenie instrumentalnego podejścia i upolitycznienie sztucznej inteligencji, czy wręcz inteligencji w ogóle, a także systemu opresji opartego o standardzie Człowieka.

Przeciwko prometeizmowi zachodniej metafizyki, która jest gruntem dla Sztucznej Inteligencji jako „a search space for upgradable versions of Man’s software, in which humans are being programmed to become one with automated networks of domination.” Z drugiej strony przeciwko filozofii techniki połączonej z teorią krytyczną, która posługując się kategorią rozumu instrumentalnego tak naprawdę sama akceptuje warunki myślenia o technologii wyznaczone przez to, co ma krytykować.

Parisi przechodzi do pozytywnego badania tego, za pomocą jakich modeli logicznych lub epistemologicznych możemy pojąć podmiot maszynowej inteligencji, który z jednej strony opiera się redukcji do zewnętrznych źródeł sprawczości, jak biofizyczne dane środowiska lub walka klas, a z drugiej ujawnia własną formę racjonalności, niesprowadzalną do modelowanego na samo-świadomości podmiotu transcendentalnego, jakiego oczekiwał od ogólnej sztucznej inteligencji Negarestani.

[https://aaaaarg.fail/upload/domenico-quaranta-hyperemployment.pdf](https://aaaaarg.fail/upload/domenico-quaranta-hyperemployment.pdf)

_Improper Commonness: The Surrogate Economy of Artificial Intelligence_

The phrase “less-than-human intelligence” is meant to describe the dehumanisation of racialised and gendered bodies in the Western epistemology of progress and civilisation. This entails the double mirroring position of this epistemology for which technological progress is granted by the surrogate labour of disenfranchised workers as much as the latter is maintained in the less-than-human state. Similarly, this phrase also refers to the assumption that machines’ intelligence is inferior to human reason. However, this article is not sharing the argument that “less-than-human intelligence” has to become equal to human reason, but rather challenges the logic of division and opposition between human and machine.

“According to Atanasoski and Vora, the technoliberal articulation of today’s racial capitalism works to conceal the uneven racial and gendered relations of power articulated with and through machines.”

Da Silva

racial grammar // An ethico-political program that does not reproduce the violence of modern thought requires re-thinking sociality from without the modern text. Because only the end of the world as we know it, I am convinced, can dissolve cultural differences’ production of human collectives as “strangers” with fixed and irreconcilable moral attributes. This requires that we release thinking from the grip of certainty and embrace the imagination's power to create with unclear and confused, or uncertain impressions, which Kant (1724-1804) postulated are inferior to what is produced by the formal tools of the Understanding. A figuring of The World nourished by the imagination would inspire us to rethink sociality without the abstract fixities produced by the Understanding and the partial and total violence they authorize—against humanity's cultural (non-white/non-European) and physical (more-than-human) “Others.”


Plan

1a stawka Parisi- problem: technologia jako autonomiczna i nieludzka siła, albo podmiot, albo sprawczość, albo warstwa organizacji złożoności o nieostrych granicach, które z pewnych perspektyw czasem bardziej staje się instrumentem lub przedłużeniem ciała
1b stratyfikacja produkcji wiedzy: kapitalizm&kolonializm - nowoczesna filozofia transcendentalna - nauka - infrastruktura komputacji - platformy - estetyka apokalipsy
1c problem relacji między autonomią technologii a jej stratyfikacją a filozofia techniki i teoria krytyczna
1d przemiana racjonalności -> techniki kontroli wektora informacji: rekursja, predykcja, kontinuum topologiczne -> otwarcie automatyczności na przygodność

2a definicja algorytmu i problem stopu - Dowek, Hilbert, Godel, Turing
2b odrzucenie różnych ujęć algorytmów -> algorytm jako praktyka społeczna
2c liczba Omega -> uczenie się uczenia -> hipotezy o hipotezach i logika abdukcyjna
2d post-instrumentalne ujęcie algorytmów -> instrument/środek jest zawsze czymś więcej niż cel

3a onto-epistemologiczna autoimmunizacja Człowieka Uniwersalnego jako pryzmat instrumentalizacji technologii oraz czarności
3b apokalipsa jest dramatyzacją rekursywnej logiki - jedną z możliwych, określoną formą panowania nad czasem
3c kosmokomputacja jako eksperymentowanie z różnymi logikami, jak logika ludyczna
3d komputacja bez oddzielalności i postapo abolicjonizm