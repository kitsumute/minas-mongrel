---
title: Przeprogramowanie decyzjonizmu
isDraft: false
description: Zamiast ogłaszać koniec myślenia metafizycznego i jego zwieńczenie w instrumentalności, ważniejsze wydaje się, aby powrócić tylnymi drzwiami do krytyki rozumowania instrumentalnego, ponownie otwierając pytanie o to, jak myśleć w kategoriach środków, poprzez które błąd, nieokreśloność, losowość i niewiadome w ogóle stały się częścią technicznonaukowej wiedzy i rozumowania maszyn.
pubDate: 20 February 2024
coverImage: ../../assets/20211105-164ALTERNATIVEKYOTOin宮津天橋立.jpg
coverAlt: description
tags:
  - Postprawda
  - Luciana_Parisi
  - Tłumaczenie
  - Algorytmy
  - Heidegger
  - Komputacja
  - Teoria_Krytyczna
---
<sub><sub>photo: ©️ALTERNATIVE KYOTO 2021 Imagination as a Form of "Capital";</sub></sub><sub><sub> Ryoji Ikeda, instalacja *data.flux*  </sub></sub>

<br>

Luciana Parisi

<br>

Polityka postprawdy jest sztuką inscenizowania starych przekonań tak, jakby były nowe, przy pomocy afektywnych predyspozycji lub znanych bądź wyrażonych już reakcje. Algorytmy mają za zadanie korzystać z tych predyspozycji lub reakcji, zapisanych w formie losowych śladów danych pozostawianych przez nas podczas wyboru tego lub innego utworu muzycznego, tej lub innej pary spodenek, tej lub innej platformy streamingowej. Innymi słowy, maszyna komputacyjna postprawdy nie kieruje się wewnętrzną, binarną logiką albo/albo, a zamiast tego podąża za tą logiką, jaką pozostawiamy w naszych przypadkowych selekcjach. Jeśli przyjmiemy, że w polityce postprawdy istnieje maszyna komputacyjna, to maszyna ta nie jest już cyfrowa, ponieważ nie zajmuje się weryfikacją i wyjaśnianiem problemów. Przeszła raczej na metacyfrową logikę, ponieważ nie zajmuje się już korelacją między prawdami lub ideami z jednej strony, a dowodami lub faktami z drugiej, a zamiast tego dzięki algorytmicznej kwantyfikacji afektów została owładnięta przez nowy poziom zautomatyzowanej komunikacji.

Metacyfrowa maszyna polityki postprawdy należy do zautomatyzowanego porządku komunikacji, zaprojektowanego dla niekończącej się eksploracji odizolowanych i powtarzalnych zachowań, które moglibyśmy nazwać *postępowaniami*. To sprawczości (*agencies*) lub wzorce działań, które są w wystarczającym stopniu dyskretne lub spójne, aby mogły zostać rozpoznane przez maszynową inteligencję. Maszyneria polityki postprawdy stosuje heurystyczne testowanie odpowiedzi w celu rejestracji tego, jakie ewolucje, zmiany, adaptacje i rewolty zachodzą w postępowaniach. Nie jest to po prostu statystyczna kalkulacja prawdopodobieństwa zgodnie z tym lub tamtym trendem w użyciu danych, a całkowita obojętność na pobierane i przesyłane dane, które służą jedynie jako tło. A jednak treść danych nie jest trywialna. Przeciwnie, maszyna komputacyjna pociąga za sobą granularną analizę danych przeprowadzaną przez algorytmy, które otwierają potencjał tych treści do przekierowania na nieznane wcześniej cele. Innymi słowy, komputacyjna obojętność na binarne rozwiązywanie problemów zbiega się z nowym imperatywem: *technologicznym decyzjonizmem*, który bardziej ceni szybkie podejmowanie jasnych decyzji niż podejmowanie właściwych. Dla decyzjonizmu najbardziej właściwe jest to, co jest najbardziej poprawne. Gdy Mussolini wygłaszał przemówienie w parlamencie w 1925 r., biorąc pełną odpowiedzialność za morderczy chaos, jaki wywołał jego reżim, i mimo wszystko wzywając swoich przeciwników do usunięcia go, praktykował on decyzyjonizm kosztem logiki binarnej, która dyktowałaby, że jeśli Mussolini jest odpowiedzialny, to powinien zrezygnować. Zamiast tego dyktator deklarował, że jest odpowiedzialny i że pozostaje na stanowisku. Dzisiaj, to maszyny wygłaszają te przemówienia za nas.

<br>

**Zdecyduj się nie decydować a rezultaty same przyjdą**

Historia komunikacji, która osiąga rezultaty poprzez *unieważnianie prawd* i *fabrykowanie faktów, a nie ich odkrywanie*, musi uwzględniać co najmniej trzy historyczne momenty w rozwoju maszynowej inteligencji i formowaniu się maszyny metacyfrowej. Pierwszy okres rozciąga się między latami 40. a 60. XX wieku, związany z powstaniem cybernetycznej infrastruktury komunikacji i wprowadzeniem logiki komputacyjnej do procedur decyzyjnych. W drugim, lata 70. i 80. XX wieku, nastąpiło przejście do interaktywnych algorytmów oraz systemów eksperckich i systemów wiedzy. Trzeci, od lat 80. aż do 00. XXI wieku, przekierował uwagę na inteligentnych agentów, algorytmy uczenia maszynowego (*machine learning*) i logikę *big data*. Wraz z wejściem do społecznej kultury komunikacji, te form zautomatyzowanej inteligencji stały się również centralnym zagadnieniem technologicznie nastawionej teorii krytycznej, nieustannie ostrzegającej nas przed automatyzacją procesu decyzyjnego, w której przetwarzanie informacji, logika komputacyjna i cybernetyczne sprzężenia zwrotne zastępują samą strukturę, język i zdolność myślenia poza tym, co już znane.

W eseju *Koniec filozofii i zadanie myślenia* (1969) Martin Heidegger argumentuje, że od późnych lat 40. XX wieku postęp cybernetyki – technonauki o komunikacji i kontroli – wyznaczył moment zwieńczenia samej zachodniej metafizyki[^1]. Nie tylko oznacza to, że filozofia staje się weryfikowalna i możliwa do dowiedzenia poprzez testowanie, ale także, że prawdy naukowe zostają podporządkowane skuteczności wyników. Rozumowanie instrumentalne cybernetyki, zastępując sądy wyprowadzone z założonych kategorii operatywnością stanów prawdy realizowaną przez maszyny, wchłania zachodnią metafizykę w całości. Technonauka nie mogła już dłużej pozostawać w służbie filozofii. Idee nie są tutaj po prostu przedstawiane lub udowadniane, lecz przetwarzane jako informacje. Nowa technonauka komunikacji uruchamia nowy język myśli wbudowany w wejścia i wyjścia obwodów informacji, zgodnie z którymi programuje się działania w celu osiągnięcia serii rezultatów.

Jeśli według Heideggera koniec filozofii jest „skupieniem w najbardziej skrajnych możliwościach”, to dlatego, że rozwój nauk i ich oddzielenie od filozofii doprowadził do przekształcenia filozofii w „empiryczną naukę o człowieku”[^2]. Nigdzie nie jest to bardziej namacalne niż w postępie cybernetyki i jej staraniach, by „określić człowieka jako istotę działającą i społeczną. Jest ona bowiem teorią sterowania planowaniem i organizacją ludzkiej pracy. Cybernetyka przekształca mowę w wymianę wiadomości. Sztuki stają się sterowanymi i sterującymi instrumentami informacji”[^3]. Gdy filozofia staje się tylko jedną z nauk we wzajemnej komunikacji z innymi, traci swoją metafizyczną totalność. Rola wyjaśniania świata i miejsca „człowieka na świecie” zostaje ostatecznie rozbita przez technologię.

W tych nowych warunkach techno-wymazywania metafizycznej prawdy Heidegger nalega, aby nowe zadanie myślenia leżało poza podziałem na racjonalne i irracjonalne. Ponieważ myślenie zawsze pozostaje ukryte w irracjonalności systemów, nie można tak naprawdę udowodnić, że ono istnieje. Z tego punktu widzenia, za Arystotelesem stawia pytanie o to, w jaki sposób można rozpoznać, czy i kiedy myślenie wymaga dowodu, i jak można doświadczyć tego, co nie potrzebuje dowodu[^4]. Dla Heideggera jednak tylko *nieskrytość* – warunek, w którym myślenie nie może zostać nieskryte – może być warunkiem prawdy. Prawda nie będzie tu oznaczała pewności wiedzy absolutnej – a zatem nie będzie należała do dziedziny naukowej epistemologii. Z tego punktu widzenia, skoro cybernetyczny porządek technonaukowej wiedzy dotyczy głównie osiągania rezultatów, nie może nam nic powiedzieć o prawdzie, ponieważ ta ostatnia pociąga za sobą nieskrytość tego, czego nie można wykazać – ponieważ myślenie zawsze skrywa się w irracjonalności systemów. Prawdy muszą zatem leżeć poza tym, co już jest znane. Dlatego właśnie w epoce pozbawionej znaczenia komunikacji, zdaniem Heideggera, należy obrócić zadanie myślenia w metodę uczenia się sposobów myślenia[^5].

To właśnie nowe wyobrażenie o tym, jak myśleć w epoce automatycznego poznania, nawiedza dzisiejszą politykę postprawdy. Znajdujemy się w impasie: nie możemy powrócić do dedukcyjnego modelu prawd idealnych, ale tak samo nie możemy polegać na metodzie indukcyjnej lub prostym sprawdzaniu faktów w celu weryfikacji prawdy. Jak przezwyciężyć ten impas? Trudno o zmianę perspektywy na to, czym może być technopolityka, bez próby rozwikłania najpierw tego fundamentalnego węzła łączącego filozofię i technonaukę, którego wciąż niepokoi twierdzenie Heideggera o tym, że transformacja metafizyki – niemożliwego do zademonstrowania warunku myślenia – w cybernetyczne obwody komunikacji wymaga artykulacji myślenia poza rozumem i jego instrumentalnością.

Jako takie, dziedzictwo tej krytyki myślenia nadal wydaje się nie dopuszczać kwestii rozumowania instrumentalnego dziś, gdy maszyny sztucznej inteligencji lub boty przekodowały krytyczną perspektywę na ideologię prawdy i data-empiryzm sprawdzania faktów. Zamiast ogłaszać koniec myślenia metafizycznego i jego zwieńczenie w instrumentalności, ważniejsze wydaje się, aby powrócić tylnymi drzwiami do krytyki rozumowania instrumentalnego, ponownie otwierając pytanie o to, *jak myśleć* w kategoriach środków, poprzez które błąd, nieokreśloność, losowość i niewiadome w ogóle stały się częścią technicznonaukowej wiedzy i rozumowania maszyn.

<br>

**Uczyć się myśleć**

W tym celu należy przyjrzeć się bliżej historycznym próbom w cybernetyce i komputacji podejmowanym od końca lat 40. do 80. XX wieku, by przedstawić modele zautomatyzowanej inteligencji, które nie opierały się na dedukcyjnej logice znanych prawd. Odkąd stosowanie indukcyjnego pozyskiwania danych i heurystycznego testowania przesunęło punkt ciężkości badań nad sztuczną inteligencją z trybu walidacji na stawanie się trybem odkrywania, założenia teorii krytycznej, zgodnie z którymi technonauki miałaby wyczerpać metafizykę w już pomyślanej – lub w zwyczajnej komunikacji – muszą ulec rewizji. To właśnie uświadomienie sobie ontycznego limitu technonauki popchnęło cybernetykę i komputację poza racjonalne systemy symboliczne w kierunku eksperymentowania z *wiedzą-jak* – to znaczy z *uczeniem się uczenia* – która obecnie jest kluczowa dla obrazu nadzoru nad komunikacją społeczną typu bot-to-bot w epoce postprawdy i post-faktu. Racjonalny system zachodniej metafizyki nie zostaje po prostu zrealizowany lub zaktualizowany wraz z cybernetyką i komputacją, lecz raczej ulega całkowitej mutacji, za sprawą której wieczna podstawa prawdy wreszcie wkracza w zmienne koleje losu materialnych przygodności. W cybernetycznej instrumentalności prawda jako wiedza zostaje zastąpiona przez środki poznania, co ustanawia metafizyczny wymiar maszynowej wiedzy pochodzącej z jej automatycznych funkcji uczenia się i przewidywania. A jednak w tym gładkim racjonalnym systemie nie można już pojmować myślenia jako tego, co jest poza lub co pozostaje nieskryte w niewidocznych lukach transparentnego aparatu komunikacji. Wydaje się, że zamiast tego należy uwzględniać przetwarzanie tego, co niekomputowalne, (nieokreślonego myślenia) w rozumowaniu maszynowym jako nowoczesnego warunku, poprzez który instrumentalność również oznajmiła, że same środki są krokiem poza to, co mogą zrobić. Ta transcendentalna instrumentalność otwiera pytanie o relację między działaniem a myśleniem, która leży u podstaw krytyki technologii. Dlatego, podczas gdy współczesna proliferacja postprawdy i post-faktycznej polityki wydaje się być konsekwencją końca zachodniej metafizyki zapoczątkowanego przez cybernetykę i komputację, konsekwencje metafizyki maszyn nie zostały jeszcze w pełni uwzględnione w kontekście powstania nie-ludzkiego myślenia. Ale co to znaczy, że maszyny mogą myśleć? Czy krytyka technologii, od Heideggera po Deleuze'a, a nawet Laruelle'a[^6], nie przekonywała, że immanencja myśli przechodzi przez nierefleksyjne i niedecyzyjne maszyny? A jeśli tak, to czy postprawda i polityka post-faktyczna są rzeczywiście tylko najbardziej widocznymi konsekwencjami tego, jak irracjonalne myślenie przenika najbardziej racjonalny system? A jednak istnieje możliwość innego podejścia do kwestii nieludzkiego myślenia w ramach logiki maszyn oraz w kategoriach powstania maszynowej epistemologii, w której stawką są złożone poziomy mediacji, a nie bezpośredniość między działaniem a myśleniem.

Już w latach 40. Walter Pitts i Warren McCulloch we wpływowej pracy na temat sieci neuronowych zaproponowali zastąpienie dedukcyjnego modelu rozumowania matematycznego opartego na prawdach symbolicznych heurystycznymi metodami prób i błędów, które pozwoliłyby maszynom uczyć się na poziomie abstrakcyjnym, a nie tylko za pomocą sensomotorycznej reakcji zwrotnej. Jak wskazał historyk cybernetyki, Ronald Kline, już te matematyczne sieci neuronowe koncentrowały się na poziomach losowości w sieci, zamiast po prostu polegać na homeostatycznej funkcji sprzężenia zwrotnego[^7]. Neuronowy model wiedzy Pittsa i McCullocha pokrywał się jednak przede wszystkim z koneksjonistycznym poglądem na inteligencję, łącząc sztuczne neurony z zapisem matematycznym, wiążąc biologiczne odpalanie neuronów z emanacją pojęć. Model ten wykorzystywał uczenie się algorytmów jako narzędzia reprezentacji głównie do wyjaśniania funkcji poznawczych[^8]. Ponieważ jednak pojedynczy neuron mógł obliczyć tylko niewielką liczbę predykatów logicznych, a zatem był niewystarczający do wyjaśnienia złożoności myślenia równoległego, model znalazł się w martwym punkcie w badaniach nad sztuczną inteligencją po latach 80.

Dopiero od późnych lat 80. i w 90., po tak zwanej „zimie SI”, nowe próby automatyzacji rozumowania wprowadziły sub-symboliczne ujęcie inteligencji, które w znacznej mierze przyjęło niededukcyjne i heurystyczne metody testowania wyników, co pozwoliło algorytmom uczyć się z niepewnych lub niepełnych informacji. Dzięki indukcyjnym metodom wyszukiwania i przekazywania danych algorytmy uczyły się – lub *trenowały w czasie* – na stosunkowo niewielkim tle danych. Zamiast po prostu weryfikować wyniki zgodnie z określonymi aksjomatami, algorytmy stały się performatywne w stosunku do danych. To znaczy, poprzez rekurencyjne i probabilistyczne kalkulacje algorytmy nie tylko wyszukują informacje, ale także wyodrębniają i tworzą wzorce.

Pod koniec lat 90. normatywne (*rule-bound*) zachowanie algorytmów stało się ewolucyjne: zaczęły adaptować się i mutować w czasie, tj. w trakcie pobierania i przesyłania danych. Eksperymenty z genetycznymi i ewolucyjnymi algorytmami ostatecznie przekształciły uczenie maszynowe jako metodę weryfikacji dowodów, tworząc sieci neuronowe wyposażone w ukryte warstwy korespondujące ze stanem pamięci komputera, które równolegle wykonują inny zestaw instrukcji[^9]. Generalnie, sieci neuronowe o większej głębokości warstw mogą wykonywać więcej instrukcji w jednej sekwencji. Na przykład, tryb uczenia maszynowego nazywany propagacją wsteczną (*backpropagation*) trenuje sieci za pomocą ukrytych warstw, dzięki czemu ewoluować mogą prostsze jednostki obliczeniowe. Wiemy, że algorytmy propagacji wstecznej są narzędziem data-miningu używanym do klasyfikacji, klastrowania i przewidywania. Gdy użyta na przykład do rozpoznawania obrazu, ta metoda uczenia maszynowego może obejmować trenowanie pierwszej warstwy algorytmu, by uczyła się rozpoznawania linii i rogów. Druga warstwa będzie uczyła się widzieć kombinacje tych linii, składające się na cechy, takie jak oczy i nos. Trzecia warstwa może następnie połączyć linie i uczyć się rozpoznawać twarz. Jednak przy użyciu propagacji wstecznej wyrażone zostaną tylko wcześniej wybrane cechy. W rezultacie, tło danych, z których cechy mają zostać wydobyte, jest już znane, przez co uprzedzenia płciowe i rasowe, na przykład, zostają już zakodowane w zbiorach danych lub są ślepe, czyli niewidoczne dla algorytmów. Zamiast liczyć na zapewnienie obiektywności reprezentacji danych, należy raczej w uczeniu maszynowym widzieć wzmacniacz istniejących uprzedzeń, które ujawniają się w łączeniu słów i obrazów w automatycznej klasyfikacji i przewidywaniu[^10].

Zamiast odgórnego programowania funkcji, algorytmy adaptacyjne w sieciach neuronowych przetwarzają dane z coraz większą prędkością, ponieważ pobierają i przesyłają dane bez przeprowadzania dedukcyjnych wnioskowań logicznych. Jednak zdaniem Katherine Hayles, inteligencja algorytmiczna nie jest bezmyślna, a raczej należy rozumieć ją jako nieświadomościową (*nonconscious*) formę poznania, rozwiązującą złożone problemy bez użycia języków formalnych lub wnioskowania dedukcyjnego. Wykorzystując niskie poziomy organizacji neuronowej oraz iteracyjne i rekursywne wzorce zachowania stanu (*preservation*), algorytmy te uczą się indukcyjnie, to znaczy, rozwijają złożone postępowania, pobierając informacje z określonych agregatów danych. Hayles zwraca jednak uwagę, że emergencja, złożoność, adaptacja i fenomenalne doświadczenie poznawcze nie pokrywają się w prosty sposób z materialnymi procesami lub funkcjami tych elementów poznania[^11]. Nawet jeśli algorytmy wykazują nieświadomościową inteligencję, nie oznacza to, że działają bezmyślnie. Ich sieciowe i ewolucyjne uczenie nie może być redukowane do ich funkcji materialnych lub – inaczej to ujmując – do ich funkcji wykonawczych.

W przeciwieństwie do Lorraine Daston, według której procedury algorytmiczne są bezmyślnymi zestawami instrukcji, które zastąpiły *logos* przez *ratio*[^12], Hayles argumentuje, że algorytmiczne procedury nieświadomościowego poznania są przekształcane w interakcji między danymi i algorytmami, danymi i metadanymi oraz algorytmami i innymi algorytmami, co definiuje uczenie maszynowe jako medium czasowe, w którym wektory informacji nieprzerwanie zbiegają się i rozchodzą. Ponieważ według Hayles uczenie maszynowe jest już przejawem niskopoziomowych działań nieświadomościowego poznania wykonywanych z niedostrzegalną lub afektywną prędkością, nie można nadal utrzymywać, że poznanie jest spójne czasowo, tj. łączące przeszłość z teraźniejszością lub przyczyny ze skutkami. Zdaniem Hayles, informacji nie można po prostu zedytować w celu dopasowania do oczekiwań. Nieświadomościowe poznanie inteligentnych maszyn ujawnia przesunięcia czasowe, które nie są od razu dostępne dla świadomego poznania ludzkiego. Ten emergentystyczny pogląd na nieświadomościowe poznanie kwestionuje centralność ludzkiej rozumności na rzecz współewolucyjnej infrastruktury poznawczej, w której algorytmy nie przystosowują się biernie do pobieranych danych, lecz ustanawiają nowe wzorce znaczenia poprzez gromadzenie, dopasowywanie i selekcję danych. Z tego punktu widzenia, jeśli indukcyjny model prób i błędów umożliwia maszynom komputacyjnym nawiązywanie szybszych połączeń, oznacza to również, że algorytmy uczą się rozpoznawać wzorce, a tym samym powtarzać je bez konieczności przechodzenia przez cały łańcuch przyczynowo-skutkowy oraz bez konieczności poznania ich zawartości.

Ponieważ jednak algorytmy zaczęły trenować na coraz większych zestawach danych, ich zdolność wyszukiwania nie jest ograniczona do znanych już prawdopodobieństw. Zamiast tego algorytmy nabierają coraz bardziej instrumentalnego podejścia do danych, eksperymentując z metodami interpretacji, nazywanymi przez Hayles „technogenezą”, wskazującą na instrumentalną transformację „tego, jak możemy myśleć”[^13].

Jednak w ciągu ostatniego dziesięciolecia ta instrumentalna transformacja dotknęła również tego, w jaki sposób algorytmy mogą myśleć pomiędzy sobą. Od 2006 roku, wraz z pojawieniem się algorytmów uczenia głębokiego (*deep learning*), nowy kierunek badań nad komputacją nieznanych danych stał się centralnym elementem ewolucji infrastruktury sztucznych sieci neuronowych. Zamiast mierzyć szybkość danych i przypisywać im znaczenie zgodnie z częstotliwością przesyłania danych, algorytmy głębokiego uczenia raczej pobierają właściwości utworu, obrazu lub głosu, aby przewidywać treść, znaczenie i kontekstowe działania danych. W tym przypadku algorytmy nie tylko uczą się na podstawie danych, ale także na podstawie innych algorytmów, ustanawiając coś w rodzaju meta-uczenia się z ukrytych warstw sieci, skracając odległość od punktów węzłowych podczas przeprowadzania granularnej analizy treści danych. Z tego punktu widzenia algorytmy uczenia maszynowego nie tylko postępują zgodnie z nieświadomościowymi wzorcami poznania danych, ujawniając luki w totalizujących systemach racjonalnych, ale zdają się także tworzyć nowe łańcuchy rozumowania, które czerpią z minimalnych wariacji w treściach danych w celu ustalenia maszynowego znaczenia ich użytku.

To ukierunkowanie na treści danych radykalnie różni się od koncepcji informacji w systemach komunikacyjnych w latach 40. i okresie powojennym. Na przykład dla Claude'a Shannona treść danych sprowadzała się do jej funkcji wyliczeniowej, a informacje miały być pozbawione kontekstu, znaczenia lub specyfiki. Dzięki głębokiemu uczeniu, *big data* i *data mining* algorytmy mogą mierzyć najmniejsze różnice w treściach i kontekście danych, ponieważ zostają one przewidziane w użytkowaniu urządzeń cyfrowych (od satelit po kamery CCTV, od telefonów komórkowych po korzystanie z aplikacji i przeglądanie stron internetowych). To, co czyni uczenie maszynowe nową formą rozumowania, to w istocie nie tylko szybsza i większa agregacja danych, ale także nowa modalność kwantyfikacji lub rodzaj jakościowej kwantyfikacji opartej na ewoluujących wariacjach danych. Można tu mówić już o transcendentalnej jakości instrumentu komputacyjnego, odsłaniającego lukę między tym, co maszyny robią, a tym, jak myślą.

Innymi słowy, algorytmy głębokiego uczenia nie tylko uczą się na podstawie użytkowania, lecz także *uczą się uczyć* na temat treści i kontekstu danych (wyodrębniając sposoby użycia treści w różnych klasach, płciach, rasach, lokalizacjach geograficznych, reakcjach emocjonalnych, działaniach społecznych, preferencjach seksualnych, trendach muzycznych itp.). Już samo to wskazuje na tendencję maszyn do nie tylko reprezentowania tej lub innej znanej treści, albo odróżniania jeden wyniku od drugiego, lecz także wytwarzania własnej formy wiedzy, tj. rozumowanie poprzez niepewność i z nią. Można zauważyć, że konsekwencją tego typu uczenia wydaje się być coś więcej niż niezapośredniczona ekspresja immanentnej myśli lub uspokajająca eksplozja irracjonalności w racjonalnych systemach. Uczenie maszynowe obejmuje raczej rozszerzone poziomy mediacji, w których niepewność przejawia się w postaci niekomputowalnych form algorytmicznej automatyzacji. Nie zrywają one po prostu z kalkulacją, kwantyfikacją, czy numerycznym porządkowaniem nieskończoności. To, co niekomputowalne wkracza w złożony proces dopasowywania mediacji, obejmujący strukturyzację losowości podczas algorytmicznego wzorcowania nieokreśloności. Nie należy zatem rozpatrywać uczenia maszynowego wyłącznie w kategoriach tego, co robią algorytmy, tj. jako modelu odtwarzania uprzedzeń zawartych w sposobach użytku, kontekście i znaczeniu danych. Jednocześnie należy oprzeć się pokusie uznania algorytmów jedynie za miejsca manifestowania się nieświadomościowych lub irracjonalnych potencjałów myślenia. Chcę zamiast tego zasugerować, że bardzo ogólna zasada uczenia się maszyn powinna byś krytycznie rozpatrywana w kategoriach rodzącej się transcendentalnej instrumentalności: to, co maszyny robią, nie pokrywa się i nie powinno pokrywać się z możliwościami maszynowego myślenia. Nie tylko oznacza to, że myślenie wykracza poza zwykłą pragmatykę, ale też, co istotniejsze, pragmatyczne rozumowanie aspiruje do budowania myśli poprzez uznanie, że przyszłe tryby działania mogą przekształcać warunki wiedzy-jak. Tutaj to, co irracjonalne, nie jest poza rozumowaniem, lecz odsłania obce możliwości oferowane przez ogólną praktykę rozumowania w zakresie mediacji zmian i działań technospołecznych.

Jeśli ta krytyka uczenia maszynowego aspiruje do zmiany perspektywy na możliwości krytycznej teorii automatycznego myślenia, to nie może ona jednak przeoczyć faktu, że algorytmiczna kontrola i rządzenie wiążą się z mikrotargetowaniem populacji poprzez konstrukcję alternatywnych faktów mających na celu wzmacnianie istniejących przekonań. Ewolucyjna dynamika uczących się maszyn pokazuje jednocześnie, że czas komputacji, łącznie z ukrytymi warstwami rosnącej sieci, również zmusza algorytmy do strukturyzowania losowości poza tym, co jest już znane. Jeśli maszyna jest, przypuśćmy, zasilana danymi należącymi do już znanych kategorii, klas i form, po rozpoczęciu procesu obliczeniowego dane te zostają uwzględnione w algorytmicznym wyszukiwaniu skojarzeń, które łączą mniejsze części danych, dodając ukryte poziomy czasowości do całości obliczeń. Zapewnia to algorytmom możliwości uczenia się, które wykraczają poza to, co zostało wprowadzone do systemu.

Z tego punktu widzenia, jeśli utrzymujemy, że algorytmy są bezmyślne i nieświadomościowe, to twierdzimy również, że kontrola komputacyjna skutkuje jedynie reprodukcją ideologicznej i dyskursywnej struktury władzy, którą dane miałyby podtrzymywać. Innymi słowy, nie ma znaczenia, czy sugeruje się, że maszynowa architektura algorytmów i danych jest kolejną formą ideologicznego projektu (nasyconego decyzjami ludzkimi), czy że ostatecznie maszyny są bezmyślne i dlatego mogą działać empirycznie (po prostu do weryfikacji danych). To, czego wydaje się tu brakować to spekulatywna krytyka uczenia maszynowego, która postrzegałaby maszyny jako coś więcej niż zwykłe instancje instrumentalnego rozumowania, czy naczynia wiedzy, które mogą w najlepszym razie podążać za binaryzmami Zachodniej metafizyki, dedukcyjnymi prawdami i indukcyjnym sprawdzaniem faktów, ale szybciej. Chociaż pogląd ten ujawnić to, że powiązanie władzy i wiedzy jest obecnie oparte na istniejących przekonaniach i granularnych agregatach danych, to nie oferuje on krytycznego podejścia do technologii, które mogłoby zmieść na bok Heideggerowską prognozę przekształcenia zadania myślenia przez technonaukę, zastępującego prawdę efektywnością postępowania zgodnego z regułami.

Krytyczna teoria automatyzacji powinna zamiast tego zacząć od próby obalenia autopojetycznej diady rozumowania instrumentalnego, w której maszyny albo wykonują aprioryczne rozumowania, albo redukują rządy rozumu (prawa i prawdy) do brutalnej siły i reaktywnych odpowiedzi. Innymi słowy, krytyka ta powinna odrzucić pogląd, że technonauka dopełnia marzenia zachodniej filozofii o rozumie i w zamian dążyć do obalenia wiedzy technonaukowej oraz rozumu filozoficznego za pomocą eksperymentów z granicami sztucznej inteligencji. Mikrotargetowanie populacji obejmuje więc nie tylko reprodukcję uprzedzeń w agregatach danych i za ich pośrednictwem, ale także algorytmiczne opracowanie wszelkich danych możliwych do urasowienia i upłciowienia, a przez to w pewnych okolicznościach do sklasyfikowania jako potencjalny wróg.

Ale w jaki sposób rozumieć te korelacje między końcem prawdy i faktu a transformacją cybernetycznych stanów binarnych w formy nieświadomościowego poznania i metacyfrowego przetwarzania uczenia, w których algorytmy nie tylko wykonują treści danych, ale uczą się, jak się uczyć, a tym samym uczą się jak uwzględniać nieokreśloność w rozumowaniu? Czy wystarczy zrzucić winię na bezmyślne technonaukowe kwantyfikowanie uprzedzonych przekonań i pragnień, czy też należy podjąć się materialistycznego ujęcia techniki, zaczynając od dokładnego badania środków, za pomocą których myślenie myśli?

Pytania te wymagają od nas przeniesienia uwagi z tego, jak inteligentne maszyny reprezentują wiedzę jako zbiór faktów w danych, na materialistyczne badania technicznej ramy myślenia w sztucznych sieciach neuronowych. Można argumentować, że od czasów II wojny światowej algorytmiczne środki myślenia należy również uważać za tryb rozumowania. Prawdą jest, że większość algorytmów uczenia maszynowego, takich jak algorytmy Netflixa, w rzeczywistości koncentruje się na konkretnym wykorzystaniu danych poprzez heurystyczną analizę korelacji danych, statystycznie dopasowując, a tym samym przewidując zawarte w danych kategorie preferencji, zgodnie z tym, co już można wiedzieć. Jednak algorytmy głębokiego uczenia – jako środki myślenia o tym, jak myśleć – obejmują nie tylko predykcyjną analizę treści i mikrotargetowanie użycia danych, ale także definiują tendencję sztucznej inteligencji do abstrahowania sposobów uczenia się o nieskończonej różnorodności treści kontekstowych. Te nieskończone różnorodności pochodzą nie tylko z algorytmicznego rejestrowania ludzkiego wykorzystania danych według częstotliwości, kontekstu i treści, ale związane są również z meta-opracowywaniem tego, w jaki sposób algorytmy zdobyły wiedzę o tych sposobach użycia.

Na przykład, w przeciwieństwie do algorytmów rekomendacji, algorytmy interpretera RankBrain obsługujące Google Ranking nie ograniczają się tylko przedstawiania do sugestii. Uruchamiają raczej meta-relacyjny poziom wnioskowania – tj. algorytm szuka wyjaśnienia nieznanych znaków w celu uzyskania informacji – poprzez hipotetyczne przypuszczenia na temat danych, obejmujące algorytmiczne wyszukiwanie nieokreślonych słów, zdarzeń lub rzeczy, dla których może nie być dokładnych haseł wyszukiwania. W przeciwieństwie do heurystycznej analizy korelacji danych między odrębnymi zbiorami, te algorytmy interpretacyjne nie tylko dowodzą, weryfikują lub potwierdzają hipotezę, ale muszą przede wszystkim opracować hipotetyczne rozumowanie w oparciu o to, co przeszukały już inne algorytmy, aby określić możliwe znaczenie brakujących w zapytaniu informacji. Algorytmy głębokiego uczenia działają na zasadzie wyszukiwania elementów zaskoczenia – to znaczy niepomyślanych informacji – które mogą wystąpić tylko wtedy, gdy system jest w stanie zachować mikropoziomy losowości, przejawiające się w ogromnych wielkościach danych, a nie po prostu eliminować je jako błędy.

Innymi słowy, ta metacyfrowa forma zautomatyzowanego poznania nie jest nastawiona na korygowanie błędów lub eliminowanie losowości; zamiast tego jest obojętna na szum entropiczny rosnących objętości danych, o ile szum ten jest właśnie częścią procesu uczenia się. Z tego powodu stawianie hipotez eksperymentalnych musi zachować nieokreśloność, tak aby mogła wiązać informację z zaskoczeniem. Chociaż można założyć, że to włączenie nieokreśloności – lub irracjonalności lub nieświadomościowej aktywności – do procesu komputacyjnego jest tylko kolejnym przejawem ostatecznego techno-panowania nad rzeczywistością, istotniejsze jest tutaj by powtórzyć, że losowość stanowi rdzeń mediacji algorytmicznej i jako taka otwiera kwestię epistemologicznej władzy na centralne miejsce przygodności w funkcjonowaniu każdego racjonalnego systemu. Nie prowadzi to do koniecznej awarii systemu – tj. linii ujścia glitchu lub załamanie porządku – ale do jego hiperracjonalnej (lub surracjonalnej, przywołując określenie Bachelarda) artykulacji realnego, nieznanego, niekomputowalnego, w kategoriach mediacji technicznych, automatycznych aktualizacji i maszynowego stawania-się realnego w ich jawnie sztucznych formach.

Zamiast ustalać ogólne wyniki na podstawie poszczególnych skojarzeń pojęciowych wyprowadzonych z częstego używania konkretnych treści przez ludzi i maszyny, włączenie nieokreśloności do uczenia maszynowego dotyczy równoległości czasowej uczenia się i przetwarzania danych. To natomiast wiąże się z opracowaniem danych, które pomijają podstawowy poziom reakcji zwrotnej na gruncie znanego już wyniku.

Wiemy, że algorytmy RankBrain nazywane są również sygnałami, ponieważ dają algorytmom szeregowania stron (*page rank algorithms*) wskazówki dotyczące treści: wyszukują słowa na stronie, linki do stron, lokalizacje użytkowników, ich historię przeglądania lub sprawdzają rejestrację domeny, powielanie treść itp. Sygnały te zostały opracowane do obsługi podstawowego algorytmu Page Ranking, dzięki czemu można indeksować nowe treści informacji[^14]. Indeksując informacje, RankBrain ma interpretować wyszukiwania użytkowników poprzez wyciąganie wniosków o treści słów, fraz i zdań dzięki zastosowaniu synonimów lub list stemmingowych. W tym przypadku, na ukierunkowanie wyszukiwań algorytmicznych na już zaplanowane wyniki nakłada się algorytmiczna hipoteza, która jest narażona na nieokreśloność wyników (*outputs*) i losowe ilości informacji przechowywanych w ukrytych warstwach sieci neuronowych. Na przykład, indeksowanie obejmuje informacje dołączone do rzadkich i precyzyjnych zapytań, które służą do dodawania większej specyficzności kontekstowej do wyszukiwanych treści. Zamiast na dopasowywaniu pojęć, algorytmy RankBrain opierają się więc na nieokreśloności wyników.

Nieokreśloność stała się częścią metacyfrowej syntezy *ratio* i *logosu*. Jako taka, jest aktywnym elementem tej sztucznej formy *wiedzy-jak*, w której przechowywanie niewiadomych prowadzi do hipotetycznych wnioskowań o znaczeniu: metacyfrowa obojętność na prawdę i fakt może więc wiązać się z możliwością ponownego ujęcia wiedzy instrumentalnej jako generowania hipotez, funkcjonującej w środkach myślenia i poprzez nie. W epoce polityki postprawdy nieokreśloność w uczeniu maszynowym nie definiuje zewnętrznej przygodności zakłócającej skądinąd stabilne rządzenie informacjami. Korelacja „nowej brutalności” fałszywych i alternatywnych wiadomości ze współczesną formą automatyzacji wymaga raczej granularnej strukturyzacji niewiadomych, popychającej zautomatyzowane poznanie poza systemy oparte na wiedzy[^15]. Nieokreśloność jest zatem nieodłącznym elementem algorytmicznego generowania hipotez i dlatego nie można już ograniczać technonaukowej artykulacji prawd i faktów do powtarzających się funkcji i wykonywania tego, co już znane. Dlatego należy dalej badać, kwestionować i odkrywać na nowo korelację między polityką postprawdy a automatycznym poznaniem.

Jak przypominają nam Deleuze i Guattari, jeśli po prostu reagujemy na dominujące formy naszej epoki, skazujemy myślenie na *doksę*[^16]. W szczególności, jeśli dominujące polityczne zasady kłamstwa i zastraszania zostają ułatwione przez niepohamowane neoheurystyczne zaufanie w wyszukiwania algorytmiczne, czy niereaktywna krytyka umieszczałaby filozofię _poza_ technologią informacyjną?

Deleuze i Guattari udowadniali już, że filozofia musi bezpośrednio stawić czoła nowemu rodzajowi dogmatycznego obrazu myśli ukształtowanemu przez cybernetyczną komunikację, która nieustannie łączy przeszłość i przyszłość, pamięć i nadzieję w ciągłym kręgu teraźniejszości. Wyjście poza dominację myślenia teraźniejszości nie wymaga jednak powrotu do wiecznej prawdy – do metafizyki prawdziwych idei – którą trzeba przeciwstawić fałszowi. Jeśli cybernetyka zbiega się z informacyjną siecią wymiany komunikacyjnej, co sprzyja rozprzestrzenianiu się opinii i generowaniu konsensusu[^17], filozofia musi odwrotnie dołożyć starań, by stworzyć krytyczne pojęcia, które ewakuują obecność teraźniejszości z przyszłych obrazów myśli. Ale jak to zrobić?

Krytyka społeczeństwa komunikacyjnego Deleuze'a i Guattariego jest krytyką informatyki, marketingu, designu i reklamy[^18]. Komunikację rozumieją oni jako przedłużenie *doksy*, modelu rozpoznawania prawdy, w którym zachodzi nieskończona iteracja tego, co wszyscy wiedzą, co mówi sondaż, w co wierzy większość. Według Deleuze'a i Guattariego komunikacja zubożyła filozofię i wdarła się w mikroruchy myślenia, obracając czas w chronologiczną sekwencję możliwości, linearne zarządzanie czasem w oparciu o to, co zostało już wyobrażone, poznane lub przeżyte. W kontrze do tego, Deleuze i Guattari stwierdzają, że niewczesność musi oddziaływać na teraźniejszość, aby dać przestrzeń dla innego czasu, który nadchodzi: dla myślenia przyszłości.

W wywiadzie *O nowych filozofach i bardziej ogólnym problemie* Deleuze szczególnie ubolewa nad poddaniem myśli filozoficznej mediom[^19], w których pisanie i myślenie przekształcają się w wydarzenie komercyjne, wystawę, promocję. Deleuze nalega, aby filozofia zajmowała się formowaniem problemów i tworzeniem pojęć. Tylko niewczesne myślenie i niefilozofia filozofii umożliwi stworzenie prawdziwie krytycznego pojęcia. Ale jak odwrócić domniemane samo-wymazywanie krytycznych pojęć, które znajdują się poza techno-naukowym porządkiem komunikacji? Czy prawdziwie krytyczne pojęcie może przetrwać obojętność nowej brutalności naszego postprawdziwego i postfaktycznego świata napędzanego przez automatyczne myślenie? Czy ta nieufność wobec technonauki nie powstrzymuje ostatecznie filozofii przed konceptualnym ujęciem świata, który nadchodzi? Dlaczego filozofia nadal ignoruje maszyny myślące, które tworzą obce pojęcia, udając, jakoby maszyny nie były w stanie tego robić?

Choć stanowią dwa zupełnie oddzielne światy, można u Heideggera i Deleuze'a prześledzić ten sam wątek stawania w obronie filozofii przed technonauką, przed ubóstwem myśli w epoce automatycznego myślenia. Jeśli Heideggerowska nie skrytość prawdy ostatecznie kontempluje nieosiągalny stan ograniczony przez świadomość skończoności (zachodniej metafizyki i Człowieka), to Deleuzjańska wizja tego, co niemyślane filozofii, zmierza raczej ku twórczemu rozwijaniu możliwości, budowaniu konceptualnych person, które stawiają opór i przeciwdziałają *doksie* teraźniejszości.

A jednak panuje tu silna nieufność do technonauki. W szczególności formy instrumentalnego rozumowania wbudowane w komunikację cybernetyczną i komputacyjną nadal są tutaj utożsamiane z kontrolą jako rządzeniem. Podobnie pojęcie środka lub instrumentu rządzenia – to znaczy technologii informacyjnych – pozostaje czarną skrzynką, która nie ma żadnych celów (sama w sobie jest bezmyślnym, nieświadomościowym automatem), oprócz tych politycznie zaaranżowanych. Chociaż nie jest możliwe odróżnienie politycznych warunków prawdy i faktów od komputacyjnego przetwarzania, wydobywania i przesyłania danych, nieuwzględnianie sposobu myślenia zrodzonego z narzędzi lub środków myślenia wydaje się równie samoograniczające.

Jeśli wraz z cybernetyką i komputacją instrument kalkulujący stał się uczącą się maszyną, która wewnętrznie rzuca wyzwanie technonauce – logice dedukcyjnej prawdy i indukcyjnych faktów – dzieje się tak również dlatego, że ta forma instrumentalności ma swoje własne rozumowanie, w wyniku którego heurystyczne testowanie przesunęło się w stronę generowania hipotez, trybu myślenia, wykraczającego poza swój tryb działania. Można by zatem argumentować, że ucząc się jak myśleć, ta instrumentalna forma rozumowania wykracza poza ontyczny warunek, w jaki została wpisana przez współczesny projekt filozofii.

Ponieważ instrumenty już uprawiają politykę, należy zadać pytanie, jak przekierować brutalność instrumentalności z bezsensownego pobudzania przekonań i pragnień w kierunku dynamiki rozumowania, która pozwala na ponowne sformułowanie – a nie eliminację – celów. Jedną z możliwości podjęcia polityki maszyn jest wypracowanie filozofii innego rodzaju, wychodzącej nie tylko od tego, co niemyślane w myśleniu, ale także od nieludzkiego bycia instrumentalności, przyjęcia obcości w ramach rozumowania, która mogłaby być punktem wyjścia do wyobrażenia sobie technofilozofii, przeprogramowania myślenia przez i poprzez maszyny. Jeśli antagonizm między automatyzacją a filozofią opiera się na instrumentalnym użyciu myślenia, technofilozofia nie powinna sugerować zamiast tego opozycji, ale równoległą artykulację filozofii maszyn przyczyniających się do ponownego wymyślenia światów, prawd i faktów, które istnieją i mogą się zmieniać.

Nowa brutalność technopolityki mogłaby zostać wtedy obalona przez technofilozofię, której próby wymyślenia na nowo społecznych form rozumowania instrumentalnego można już znaleźć w historiach, kulturach i estetykach, odwracających metafizykę obecności. Na przykład architektura Nowego Brutalizmu z lat 50. i 70. XX wieku uruchomiła program życia technospołecznego, który miał na celu zniesienie sentymentalnego przywiązania do kresu „duchowości w człowieku” i przekroczenie normy ekspresji architektonicznej poprzez nieskrępowany funkcjonalizm, wyrażający surowość konstrukcji i materiałów[^20]. Nie tylko funkcjonalizm, ale przede wszystkim aformalizm i topologia wpisywały się w działania proceduralne, które starały się przekroczyć kontemplację celu poprzez nowe wyobrażenia przestrzennego doświadczenia prawd i faktów. Tutaj wszystkie media są równoległe lub zrównane ze sobą, aby połączyć ich specyficzne treści w wymiarze aformalnym – w takim, który mógłby przepracować niekompletność totalnego obrazu wspólnotowości. Połączenie materialnego świata ożywionych i nieożywionych mediów zachowuje jednak ukrytą złożoność tych odrębnych części, które mogą następnie zrewidować mediacyjne formy prawd i faktów w wielu różnych kierunkach.

Architektura Nowego Brutalizmu zamienia instrumenty myślenia w betonowe, modularne, połączone ze sobą bloki i samodzielne pojedyncze komórki, wzniesione ponad lokalnym terytorium, zjednoczone podniebnymi ulicami lub sieciami korytarzy biegnących między oddzielnymi częściami budynków. Rozumowanie instrumentalne przekształca tutaj entropiczny rozkład okresu powojennego, utrzymując betonowo zwarty ciężar przeszłości, aby rozpuścić ją w strukturalnych eksperymentach z funkcjami zadaniowymi i estetyką transparentności. Jeśli wizja Nowego Brutalizmu ułatwiała zmilitaryzowanie informacji, to nie chodziło po prostu o postęp technologii informacyjnej, ale raczej o zaproponowanie sposobów rozumowania instrumentalnego, które działają poprzez entropię, losowość lub szum, by przeprogramować kody i wartości, przejścia i mosty, treści i wyrażenia zjednoczonego obrazu tego, co społeczne.


  


[^1]: M. Heidegger, *Koniec filozofii i zadanie myślenia*, przeł. K. Michalski, w: Teksty: teoria literatury, krytyka, interpretacja, nr 4-5 (28-29), s. 9-26.

[^2]: Tamże, s. 11.

[^3]: Tamże, s. 12.

[^4]: Tamże, s. 26.

[^5]: Tamże.

[^6]: G. Deleuze, *Myśl i kino*, rozdz. 7, w *Kino II. Obraz-czas*, przeł. J. Margasiński, Gdański 2008. F. Laruelle, *The Transcendental Computer: A Non-Philosophical Utopia*, przeł. T. Adkins, Ch. Eby, Speculative Heresy, https://speculativeheresy.wordpress.com/2013/08/26/translation-of-f-laruelles-the-transcendental-computer-a-non-philosophical-utopia/.

[^7]: R. R. Kline, *The Cybernetic Moment: Or Why We Call Our Age The Information Age*, Baltimore 2015, s. 53.

[^8]: Tamże, s. 56.

[^9]: Na przykład, system sztucznej inteligencji obserwujący obraz z twarzą, na którym jedno oko jest w cieniu, może początkowo widzieć tylko jedno oko. Jednak po wykryciu obecności twarzy może wywnioskować, że prawdopodobnie znajduje się tam także drugie oko. W tym przypadku graf pojęć obejmuje tylko dwie warstwy - warstwę oczu i warstwę twarzy - ale graf obliczeń obejmuje 2n warstw, jeśli doprecyzujemy nasze oszacowanie każdego pojęcia, biorąc pod uwagę pozostałe n razy.

[^10]:  A. Caliskan, J. J. Bryson, A. Narayanan, *Semantics derived automatically from language corpora contain human-like biases*, Science 356, nr 6334 (2017), s. 183-86.

[^11]:  K. N. Hayles, *Cognition Everywhere: The Rise of the Cognitive Nonconscious and the Costs of Consciousness*, New Literary History 45, nr 2 (2014).

[^12]:  L. Daston, *The Rule of Rules*, wykład, Wissenschaftskolleg Berlin, 21 listopada 2010.

[^13]:  K. N. Hayles, *How We Think: Digital Media and Contemporary Technogenesis*, Chicago 2012.

[^14]:  R. Ridgway, *From Page Rank to Rank Brain*, 2017, https://machineresearch.wordpress.com/2016/09/26/renee-ridgway-title/.

[^15]:  R. Braidotti, T. Vermeulen, J. Aranda, B. K. Wood, S. Squibb, A. Vidokle, *Editorial: The New Brutality*, e-flux journal 83 (June 2017) http://www.e-flux.com/journal/83/142721/editorial-the-new-brutality/.

[^16]:  G. Deleuze, F. Guattari, *What Is Philosophy?*, przeł. H. Tomlinson, G. Burchell, New York 1994, s. 99.

[^17]:  Tamże.

[^18]:  Tamże, s. 10.

[^19]:  G. Deleuze, *On the New Philosophers and a More General Problem*, Discourse: Journal for Theoretical Studies in Media and Culture 20, no. 3 (1998).

[^20]:  R. Banham, *The New Brutalism: Ethic or Aesthetic?*, London 1966.